[{"content":"说在前面的 网上随便搜一下多巴胺和内啡肽能搜到很多相关的内容了，总结一下大概就是分泌多巴胺（神经传导物）获取的快乐是短暂的，为的是获得某种奖赏，而不是获得奖励本身，而且还有具有成瘾性质，且获得快乐的阈值会被提高。我们每次在此之后都会有一段懊恼期，比如刷完抖音后，感觉自己浪费了时间\n而内啡肽（内成性（脑下垂体分泌）的类吗啡生物化学合成物激素）则完全相反，他需要付出很大的努力才能获得，且获得的快乐是持续的，内心是平静的，不焦虑。目前我知道的且在做的获取内啡肽的方式有：阅读，运动，冥想\n以前自己的潜意识里知道刷抖音等那些获取短暂快乐的方式不好，但一直想不通，现在算是理解了，而且越发的激起我想看书和运动的心\n大家也可以想一下，平时自己那些行为是符合分泌多巴胺，哪些是分泌内啡肽，那种会让你更平静舒适呢？\n最近的总结/学习 人生的大部分痛苦，本质上都和它有关 ref：https://mp.weixin.qq.com/s/DgD7yj_HAZ0_gfuJeAktXw\n很多人甚至意识不到，许多表面问题的背后，都或多或少地藏着一些「羞耻感」：\n不敢靠近自己喜欢的人，害怕自己不够好、配不上，害怕被拒绝；\n在关系中不敢表达自己的真实想法和感受，受了气也要忍气吞声，跟自己内耗；\n要求自己永远保持「优秀」，犯过的一点小错也会被自己紧抓不放或严重夸大；\n「监控」自己的每一个行为和特征，以避免让人感到失态、尴尬和冒犯；\n许多人独立、强大的表面背后，是对自己在他人面前袒露和表达脆弱的坚决不允许；\n美国的心理咨询师John Amodeo博士曾这样描述「羞耻感」：\n作为一名从业40多年的心理咨询师，我将「羞耻感」视为一种复杂且具有破坏性的人类情感，具有深远的影响。我们都体验过它，但很少有人意识到它隐蔽的运作方式。当羞耻潜伏在我们的意识之外时，它可能成为摧毁我们世界的破坏性愤怒、斥责和暴力背后的原动力。\n什么是羞耻感 羞耻是一种有缺陷和不足的感觉。社会学家Brene Brown将其定义为「一种极度痛苦的感觉或经历，认为自己是有缺陷的，不值得被爱和归属。」\n羞耻感与内疚感（Guilt）不同，内疚感是当我们面对自己负有责任却不作为的时候产生的感觉，而羞耻感则关乎到我们作为一个人的内在根本。\n羞耻感是怎么来的 心理学认为，如果与父母或养育者的早期关系存在困难，会更容易形成内在自我的「羞耻感」。当有难堪的事情发生，一个孩子在感到愚蠢、无能或失败时得到了安抚和包容，Ta就更有可能对自己采取足够容忍和包容的态度。\n羞耻感也会阻碍人们寻求帮助 带着这种隐藏的情感，人们会因为害怕被暴露的耻辱感、成为被关注的对象而拒绝寻求心理咨询的帮助\n觉得最实用的10个写作技巧 ref：https://twitter.com/coolXiao/status/1554667451203276801\n删掉“我认为”、“我觉得”、“我相信”等\n你写的本来就代表你的观点，不需要再重申，另外这些词会弱化你文章的可信度\n我觉得你会喜欢这些技巧 你会喜欢这些技巧（更好） 先写标题\n写出音乐感（写短句，有节奏感）\n“triad”（三合音），只列举三个栗子\nCTA = call to action（告诉读者如何行动），让读者有所收获\n先写下眼前已经明确的，最想说的那个点子，不要考虑全文最后的呈现，先写下一句最想说的话，最想表达的点子，已经成型的想法\n简单和清晰\n不说副词\nhttps://baike.baidu.com/item/副词/2365956 当开始写草稿时，应该一鼓作气，先填满画布。我们不能犹豫，因为犹豫就会败北\n其他\n工具和软件🧰 https://nomadlist.com https://opensource-heroes.com/ 发现顶级的开源组织，项目或者开发者 这是一个类似城市宜居度指标，旨在为远程工作者提供办公地址选择，地址范围是全球。从消费，网络，娱乐，安全，天气等多方面进行评价。不是远程办公也可以看看，说不定用上了呢，哈哈 https://github.com/XingangPan/DragGAN 使用点和拖拽的方式生成图片的开源项目，目前代码还没上去，期待源码开放 https://github.com/kestra-io/kestra 任务编排，和Jenkins相比的话感觉适用范围广一点 https://databasediagram.com 数据库结构定义 https://pinboard.in/popular/ 类似于hackernews https://firewood.news/ 找到值得关注的独立博客 https://roadmap.sh/ 各种技能的学习路线图，值得一看 值得一读📰 人生的大部分痛苦，本质上都和它有关 https://motion.zajno.com/ 秀ui/ux肌肉的网站 https://samwho.dev/memory-allocation/ 描述内存的手动创建和回收后发生了什么，可交互式的展示，很舒服 https://twitter.com/GPTDAOCN/status/1658174603506900992 其实你不需要1000个AI工具 https://twitter.com/StabilityAI_JP/status/1656859810682515456 AI做广告 https://m.okjike.com/originalPosts/643bae27c567913bb53213ae?s=eyJ1IjoiNjIxN2IyZTllNzQxMGIwMDExZDg4MGRmIiwiZCI6MX0%3D 关于照片锐的问题，除了环境，光线影响外的因素 https://baike.baidu.com/item/衍射极限/2710286 极限衍射我也是去年在links的一期视频听到过，现在好好地搞懂一下原理 简单衍射是不可抗力的物理存在，经过镜头的光点成像为艾里斑（圆），当艾里斑大小平衡匹配于像素格的时候，成像质量最高 光圈恒定时（比如风光狗喜欢的F11)，用这个像素密度p去匹配CMOS的像素密度，即可不浪费的计算出相机合适的CMOS像素（画幅尺寸/像素数量）。 不同的摄影方式（人像/风光/星空等）都有相对常用的恒定光圈大小（假设镜头满足），这样就可以最大程度利用镜头和像素。 衍射极限同样适用于芯片光刻、结构光显微成像、全息成像等领域。随着百年来科学理论的不断沉淀，及微纳技术近年来的飞速发展，光学成像的魅力和应用会在未来数年间绽放光彩。 最近发生了什么事👀 https://github.com/megaease/Remembering-Haoel\n芝兰生于深谷，不以无人而不芳。\n君子修身养德，不以穷困而改志。\n","date":"2023-06-11","permalink":"https://kazma233.github.io/posts/2023-06/20230611/","tags":["newsletter"],"title":"🐱多巴胺和内啡肽"},{"content":"说在前面的 最近有一点偷懒了，没有写newsletter了，还好今天外面下雨，待在家里，没有什么计划，突然对写newsletter有了想法。虽然newsletter停写了，但是平时收集和阅读信息的习惯还是在的，可以让我捡起来马上就写，开始吧\n最近说的最多的第一个肯定还是AI了，围绕着AI出了很多相关的工具，我自己也在用GPT来提神自己的工作效率，非常好用\n另一个就是裁员的风波仍旧继续着，并且还有了升级，比如最近的领英中国的整个部门裁撤；OPPO放弃造芯，中止芯片设计业务，裁撤人数超过2000；自己身边也有前同事在新公司被毕业。现在看来，上半年还是太难了\n最近也有说新冠第二波要来了，大家还是要多注意呀，多多锻炼身体，最近我也要继续我的跑步计划了\n最近的总结/学习 关于做点什么 最近让我意识到，当你想做些什么的时候，不一定要想的特别的清楚。因为很多东西，只有开始做了，你才知道要做成什么样子，在做的时候根据自身或者外因的变化去调整，跟随自己的心去改变方向就可以了\n关于工作 思考一下为什么会有加班的问题\n倒排期问题（疯狂加班，需求完成质量差） 倒排期准确来说不是什么大问题，问题是需求没有封板，很容易在中途修改需求，甚至有时候需求都未明确，灰度状态都需要颠覆重来 设计评审被卡脖子（设计方案需要被review通过才行，但是review的那个人并没有那么多时间），同时评审也会对需求调整 有些需求过于复杂，让我站在客户的角度，都很难想象要怎么理解这些功能 丐版轮子 不知道为什么，公司以前总是很喜欢造各种各样的轮子，特别是在已经有开源实现的情况下。造的轮子大部份都是很难用，有一些轮子没有文档，代码写的还很复杂，出现bug或者想要扩展优化，简直是无从下手 事情太多 无论在任何阶段的线上bug（这个根因还是开发节奏的问题） 由于业务久远，未有沉淀，很多东西连产品都不知道，需要开发帮忙查查看逻辑（客服也是） 早晚站会，日报，周报 工具和软件🧰 类似notin的工具：AFFiNE 支持私有化部署，功能没有Notion的多 sdtools Stable Diffusion的百科，帮助弄懂一些名词有帮助 开源的代码Copilot：starcoder#installation 不确定自己网站的配色，来这里吧：happyhues Stanford Alpaca：https://github.com/tatsu-lab/stanford_alpaca LLaMA Model bark：https://github.com/suno-ai/bark Text-Prompted Generative Audio Model 自己尝试了一下，还没搞成 Airbyte：https://airbyte.com/ 关联阅读：https://www.mongodb.com/developer/products/atlas/elt-mongodb-data-airbyte/ Midjourney学习导航：https://learningpromt.wiki/docs/midjourney-learning-path Prompt教程：https://learningpromt.wiki/ 圣地巡礼：https://anitabi.cn/ MeilliSearch：https://www.meilisearch.com/ 开源，轻量搜索引擎 Dolly：https://huggingface.co/databricks 轻量AI语言模型 路由器操作系统：https://www.istoreos.com/ 值得一读📰 推特的推荐算法开源了：https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm\nB端观止：https://www.yuque.com/u1003394/fn574a\n缓存系统：https://twitter.com/bytebytego/status/1643493919169343489\nAI模型Dolly：https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA%3D%3D\u0026amp;idx=1\u0026amp;mid=2652310702\u0026amp;sn=cca0600e5572e4c2770b49f1c1be8638\n最近发生了什么事👀 塞尔达传说王国之泪发售 尼康Z8发布：https://www.nikonusa.com/en/nikon-products/product/mirrorless-cameras/z-8.html ","date":"2023-05-14","permalink":"https://kazma233.github.io/posts/2023-05/20230514/","tags":["newsletter"],"title":"🐱裁员，工作思考，AI"},{"content":"说在前面的 最近在体验AI相关的内容，感觉很神奇，像是一个新时代到来了的感觉\n最近的总结/学习 AIGC 最近AI相关的话题算是被chatGPT一夜之间给引爆了，全网到处都在传播。我的社交平台也是随便刷刷就能刷到chatGPT相关的内容\n有的人用它制定旅游计划；有人让他帮忙处理工作上的事情（写文章，周报）；甚至有的人让他充当人生的导师，咨询人生建议等等\n经过一番体验后，有人很形象的描绘了一下chatGPT：整个互联网.zip\n自己当初并没有马上去使用chatGPT，一个是由于地区限制chatGPT仅在特定地区开放，二是最近看的相关内容实在是太多了，降低了我的探索欲。不过随着chatGPT的出现，科技公司们基本上没有坐的住的，发布了很多AI相关的服务。我这也还是没能忍住好奇心，刚好最近chatGPT推出了API服务，我就在国内大佬们的代理服务上玩了一波，体验下来给我的感觉是人工智能终于不是一个哈批AI了，而是一个有丰富知识的大脑\n当然，ai也不是完美和万能的，它也会给你错误的答案，如果真的有准确度要求高的内容，还是去官方wiki寻找答案吧\n我相信随着资本和大公司的投入，将会有越来越多各种形态的AI内容出现，让我们好好期待这个时代的拐点吧\nsource：https://m.okjike.com/originalPosts/63faa0d84fa545a27b275b45?s=ewoidSI6ICI2MjE3YjJlOWU3NDEwYjAwMTFkODgwZGYiCn0%3D\nStable Diffusion 在本地也玩了一下文生图的Stable Diffusion，搭建过程很流畅，已经开始“炼图”了\n现在疯狂下载模型和lora完，开心的一匹\n#81: 你不是不会思考 | 生活奇旅 养成思考的习惯，当然这也需要练习\n我自己其实就是喜欢在来到一个问题的时候，先去思考事情是不是所看到，所描述的这样，然后再去判断要怎么解决处理。因为如果靠直觉去判断某一件事情，很容易看不全面\n主动选择、主动思考，需要付出时间和精力。但如果你越是不思考，你就越容易陷入默认模式的陷阱，你就像被束缚了起来却不自知。\n我总是想起一句话：困难的路越走越容易，容易的路越走越难。\n工具和软件🧰 SingleFile：将整个网页保存为单个HTML文件 Rath：分析你的数据，并且可视化 AwA UI：用html和css制作的UI组件，拿来copy太爽了 AI帮帮忙：看标题就只知道干嘛的了 Stable Diffusion Online：上面可以体验Stable Diffusion和找一些Prompts HuggingFace：找模型，找数据 Replicate：Machine learning doesn’t need to be so hard.Run models in the cloud at scale. awesome-ChatGPT-resource-zh：中文ChatGPR精选资源清淡 值得一读📰 https://dkb.blog/p/bing-ai-cant-be-trusted：AI的胡说八道，这里虽然说的是AI，但不仅仅特指New Bing https://mp.weixin.qq.com/s/obVI3ENpMgaq4AKZs6Hw1w secondary research（即可以不用和外界交流，纯粹自己花时间看就可以学习的东西）：看百科，搜大V的分析以及投资的文章，社交圈内的文章 primary research（即与人交流的环节）：对上述research看完后产生的思考及疑问和他人进行沟通（这要看社交圈子了，聊天的信息可能会不一样，不过大家脑海中都会有相关想法，可以汇总下） eBPF 介绍 | 酷 壳 - CoolShell 有趣产品咖啡馆 Funny café #17 - 分享一堆 ChatGpt 使用指令 | 有趣产品咖啡馆 类似的还有 https://www.explainthis.io/zh-hans/chatgpt https://newzone.top/chatgpt?tags=text\u0026tags=interpreter\u0026tags=games 社论｜尽早关闭健康码_观点频道_财新网 健康码下线为何如此难 即便其服务的政策已发生重大转变，健康码也已丧失实际功效，各地政府似乎仍未对彻底下线健康码下定决心 个人信息处理者就有义务主动删除个人信息，个人信息处理者未删除的，个人有权请求删除。在疫情结束后，集中删除和清理个人信息，不仅是个人行使被遗忘权的表现，还可作为约束公权机关权力扩张、防堵信息泄露的重要手段 而且经过三年防疫的历练，未来如果再出现疫情反复或暴发其他大规模传染病，地方政府完全可以通过更精细和更合规合法的方式进行数据收集和码化治理，而无需再像健康码一样，通过无差别全员收集、实时收集和事无巨细的方式进行突发重大公共卫生事件的应对和防控 目前适宜的做法可能是由中央统一安排部署健康码的下线和数据的删除销毁工作，以避免各地在疫情结束后仍旧各行其是。而在此过程中，广泛吸纳公众参与，引入独立的第三方监督机构，增加整个处理过程的透明度无疑也是消除公众疑虑、重新建立个人与政府间数据信赖的重要方法 法治的基本目标就是为防御国家权力的膨胀对个人权利的侵蚀。我们会明显看到，在数据技术加持下，国家与个人之间的权力势差正在不断拉大，传统法治建构起的权力制约和权利保障的机制也因数据技术而被蚕食和摧毁。因此，如何对国家权力与数据技术结合所催生的“数据霸权”保持警醒，如何避免数字利维坦的产生便成为当务之急 最近发生了什么事👀 chatGPT推出API ","date":"2023-03-12","permalink":"https://kazma233.github.io/posts/2023-03/20230312/","tags":["newsletter","AI"],"title":"🐱AI"},{"content":"概览 看着社交平台各路神仙炫自己用ai生成的美图，是不是有些许羡慕呢？看到了自己喜欢的图片，是不是也会手痒，想自己也用ai生成一些玩玩，但是又苦恼无从下手？那跟着这篇文章一起行动吧，从零开始，你也可以的，而且还很简单喔！\n本文使用github上的stable-diffusion-webui这个项目来实现本地搭建Stable Diffusion的，我整个体验下来感觉非常流畅，只有一些小坑，稍微看看wiki就解决了\n之所以是说本地，是因为在网络上有了很多可以在线的使用Stable Diffusion的网站，这用来感受ai的能力是最方便了，但也止步于此了。ai生成图片需要大量的算力，在线的服务器不可能给你分配大量的算力去生成更大的图，同时有一些参数也没法调整，所以为了我们自己更好的捣鼓，我们就需要在自己的本地机器搭建Stable Diffusion环境来生成更高质量，能有更多选项调节的图\n说了那么多，开始吧，我们一起在本地生成出自己想要的图片吧\n前置条件 硬性条件:\n良好的网络 需要有独立显卡，并且不能太差 Dependencies\n根据文档中Dependencies的内容，需要做如下操作：\n安装Python3.10.6（使用pyenv来管理python版本） 安装git(推荐使用scoop来安装) 拉取**stable-diffusion-webui的代码(git clone)，直接下载zip也可以** 再下载Stable Diffusion的模型，也就是上面Required Dependencies的第三点，下载完把这个模型直接放到models/Stable-diffusion目录就好了 Command Line Arguments and Settings\n在你上面步骤搞定了之后，应该有一个stable-diffusion-webui的目录，进入编辑一下webui-user.bat，主要是把PYTHON的路径和VENV_DIR的配置一下（在这里栽了跟头，默认里面什么都没写，找不到python的路径，我本地直接闪退，什么日志都没有），下面是我的参考：\n@echo off set PYTHON=C:/Users/${USER}/.pyenv/pyenv-win/versions/3.10.6/python.exe set GIT= set VENV_DIR=D:/path/stable-diffusion-venv set COMMANDLINE_ARGS= call webui.bat 然后运行webui-user.bat就好了，等待一会，最后会输出一个地址（Runing on local URL：http://127.0.0.1:7860），访问就能看到webui啦。中途注意看报错，有问题在网上搜索一下看看为啥，我没有遇到过问题，嘿嘿。\nWeb UI使用 试着玩了一晚上，后面继续“炼丹”，可以去civitai找模型\n加速 Xformers\n参考链接 https://huggingface.co/CompVis/stable-diffusion-v-1-4-original：模型下载地址 https://prompthero.com/stable-diffusion-prompts?version=1.4：可以去上面找prompt https://civitai.com/：模型模型模型 ","date":"2023-03-09","permalink":"https://kazma233.github.io/posts/2023-03/%E5%9C%A8%E6%9C%AC%E5%9C%B0%E6%90%AD%E5%BB%BAstablediffusion%E7%94%9F%E6%88%90%E8%87%AA%E5%B7%B1%E6%83%B3%E8%A6%81%E7%9A%84%E5%9B%BE%E7%89%87/","tags":["article"],"title":"在本地搭建StableDiffusion，生成自己想要的图片"},{"content":"说在前面的 最近AIGC相关的内容被chatGPT给引爆了，基本上到处都在刷屏。毋庸置疑，chatGPT绝对是跨革命的，未来会怎么发展我已经想不出来了\n最近的总结/学习 最近没什么时间，这周就当休息吧\n工具和软件🧰 AI工具汇总（source） https://www.futurepedia.io https://www.ainav.cn https://sharegpt.com：别人和chatGPT聊了什么 https://hamsterbase.com/zh/：HamsterBase 是一个本地优先,隐私优先的知识收集工具。 值得一读📰 https://havefun.zhubai.love/posts/2233927141735739392 这里让我想起了《成功人士的七个习惯》这本书说到，伤害我们的不是事情本身，而是我们对于事情的反应 与其在想为什么是我，不如想想我该怎么办？ https://web.okjike.com/originalPost/63dd3b109cc3de31f9123ab1 问题和情绪 https://www.infoq.cn/article/1y50p46mqc05rxlWsAKl 技术人穿越周期的生存之道是转型管理？｜展望技术管理者的 2023 最近发生了什么事👀 微软“核弹级”更新：ChatGPT亮相Bing搜索和浏览器，今天上线，免费使用 ","date":"2023-02-12","permalink":"https://kazma233.github.io/posts/2023-02/20230212/","tags":["newsletter"],"title":"🐱AI"},{"content":"说在前面的 开始写这篇newslatter的时候已经是假期的最后一天（初六）了，明天开始滚去搬砖。\n最近的总结/学习 未来道路 不知道是自己关注这块多了，还是说大环境是这样，我发现最近接触到最多的词就是自由职业或者是副业。\n随着思想的改变，发现自己也是越来越不想上班了😂，以前觉得我只要认真上班，获得工资，好好生活就好了，后来发现这个想法有点太天真了，认真上班其实就是一件很难的事情。\n现在也是考虑在完成本职工作的情况下，找一个副业做起来，看看有没有机会换一下赛道或者身份\n然后side‑project也还会继续考虑，比如infoQ这篇文章里提到的，很多大佬的side‑project就是从身边寻找灵感慢慢做大，完善的；同时多关注关注producthunt。\n加减新功能 虽然增加新功能看起来是改进产品最直接的办法，但事实上，每一个产品开发者都应当警惕特性蔓延（feature creep）的危险，也就是增加越来越多并不真正创造核心价值的功能，而且使产品变得更难以使用。在很多情况下，改进的关键在于做减法而不是做加法\n这句话摘录自：《增长黑客》，对于工具型的产品来说，真的是越简单越好，太过于复杂没有人会想要去用\n即友 作为10年的跨界从业者，我总结了三大法则：\n在行业层面，做一张行业图谱：理清公司在行业上下游以及相关产业链所处的位置，因为本质上，公司的营收（资金流动）肯定是来自行业相关方，可以使自己更具有全局视角与全景思维，与老板在宏观层面同频思考。\n在公司层面，做一张公司业务逻辑图：思考、理清公司的业务流程与逻辑，明确自己负责的业务在公司整体业务中的位置。比如一个C端app，一侧链接用户，一侧链接团队，中间即是产品本身。\n在个人层面，通过寻找信息密度大的内容载体，进行快速学习。我推荐的顺序是 报告＞图书＞新媒体。当然，你如果有行业人脉，也可以多请教不同的前辈，作为补充。\n工具和软件🧰 internetisbeautiful：用于发现一些有趣、有用、超级赞的网站，支持邮箱订阅\n竹白百科\n生日色\n值得一读📰 准独立开发者的一年，Side Project 每月4位数 | 2022年终总结\n它里面也提到了我之前的一个误区：之前我总是想把一个软件的共呢个做大、做好。实际上你应该先去把东西做出来，能用为主，然后再根据使用的情况慢慢的打磨和完善它，这样更不容易半途而废，同时做出来的东西也是更符合需求的\n2022年度技术盘点与展望：这个集合了infoQ里关于技术盘点和展望，都比较有内容，值得一看\n一个架构师在 2023 年需要掌握哪些“必杀技”？ 展望后端研发工程师的 2023：“后端难学”源于知识体系匮乏，面试时这三点是加分项 2023 中国技术成熟度评估曲线发布，六大发展趋势将影响软件研发行业 2022-2023，读懂技术圈：算是对上面的文章一个概览？\n图解 | 你管这破玩意儿叫指针？\n播客：方励：哪有二三十岁就在想自己老了怎么办的｜一席\n最近发生了什么事👀 新春快乐 深圳不再安排建设安居型商品房，实行共有产权住房 ","date":"2023-01-29","permalink":"https://kazma233.github.io/posts/2023-01/20230129/","tags":["newsletter"],"title":"🐱未来道路"},{"content":"最近买了财新通，发现上面的文章都是比较有深度和比较敢报道的，能够有更多的思考，感觉买的还挺划算的\n失业率 最近看了财新的11月城镇调查失业率升至5.7% 大城市失业率创年内次高这篇文章，在2022年底的失业率仍旧很高。受到疫情影响，经济下行，工作没有以前好找了，如果人民没有工作，那会引起很多的问题。\n工具和软件🧰 boltcss：给HTML标签换一个样式，我已经在使用了 sapic：自建图床工具。他这个还依赖redis，想自己写一个了 colorkit：有是一个配色网站，还不错，这个我还挺喜欢的 he3：开发者必备的万能工具箱，让你开发更有效率。想自己写一些自己常用的工具了 cssgr：grid布局样例，可以copy css 值得一读📰 聊聊团队协同和协同工具 The Go libraries that never failed us: 22 libraries you need to know：Go语言推荐一些常用功能推荐使用的库，还挺支持的 不上班的1000天，程序员自由职业 B 计划 - 做什么/收入/经验教训：简单简历的开发者，向大佬学习 简历指南 最近发生了什么事👀 打开国门：随着疫情的放开，新冠“乙类乙管”后，各行各业开始活络起来了，但是因为放开的太多，许多行业都还没有准备好准备 ","date":"2023-01-07","permalink":"https://kazma233.github.io/posts/2023-01/20230107/","tags":["阅读","失业"],"title":"🐾阅读、失业率"},{"content":"今年本来想好好写一个年终总结的，但是经过一而再，再而三的拖延，终于，我放弃了，按照以往肯定会列一些平时买的东西，看的书和电影，听的博客等等，现在突然不想列了，只想把现在的想法写下来\n概览🌈 今年可以说是剧烈动荡的一年，隔一段时间就会冒出一个大事件：经济下行、大公司裁员、疫情彻底放开等等，这还仅仅是我随便一想。在这多变的时间段，发生的种种事情，改变了太多人的想法，这其中也包括我。\n关于成长💗 在这一年自己可以说是真的成长了，比如：\n不再像以前一样执着某些事情 不再只关注自己，开始关注周围（社会经济，朋友间的关系，父母的生活状态等） 开始考虑一些现实的问题，做一些未来的打算 现在也不会再去纠结：\niPhone和Android使用有什么区别，新iOS和Android操作系统都添加了哪些新功能 不再考虑在线笔记有哪几款，都有什么特点，使用起来有什么感觉 不再去追一些新的数码装备 买东西开始思考：我是不是真的需要、要不隔天看看还想买吗？\n以前的自己是一个究极选择困难症，因为经常能够看到各种同类型的不同工具出现，比如RSS阅读器、笔记工具、读书软件等，翻看以前的内容也能发现自己总是想要去寻找更好的工具，并没有好好的去使用他们，多少有点本末倒置了。\n这其实有点像自己整个人的状态，总是怕错过一些什么，花费大量的精力关注一些表面的东西，都没有深入的去发掘。\n关于输入👁️‍🗨️ 今年的输入有了一些变化，原因有两个，一个是迷上了newsletter，还有就是购入了iPad Air。\n现在阅读都是在iPad Air上完成的，平时没事就翻翻邮件看newsletter，或者打开浏览器刷刷网页（财新），在有比较长的空闲时间就打开Apple的Books来看看自己下载的电子书，当然在没有安静的心思的时候，也会“爱奇艺”一会。\n今年看了大概9本书，不是很多，但是养成了读书的习惯。\n在平时通勤，会戴着耳机听一听博客，这也是我的信息输入之一，听起来比较放松，就是不是很方便记录，所以大部分时间都是拿来听故事一样的，如果实在觉得某个点说得好，就拿出手机，打开记事本记录一下，后面写东西时可以拿出来看看。\n现在看到了不错的内容，都会想着写进newsletter里，因为不是时刻都会在写作界面，我会暂时把他们保存在raindrop里，等下次写的时候，都会从里面去找素材\n关于输出✍️ 以前也有做输出的习惯，比如记笔记、画思维导图什么的。\n今年除了这些以外，还开始写newsletter了。写newsletter最大不同的一点是：以前写笔记是写给自己看，现在是写给别人看。\n在写了过去这几期后（发在了自己的博客上），感觉自己光写没有和别人交流也有点怪，毕竟是写给别人看的内容，但是却没有读者，所以新的一年打算除了往自己的博客发，再往社交平台也发一次，稍微精简，浓缩一下，看看有什么反馈。\n有价值的东西🔥 最近脑海里一直有一个想法散不去，那就是想去做一些有价值的事情或者东西。\n可能是在使用了那么多的工具之后，也有可能是自己想找工具的想法仍然挥之不去，作为程序员的我，开始总是想着要去写点什么软件。\n最近已经行动了，前面说喜欢读newsletter，就写了一个工具把不支持邮件订阅，但是支持RSS的信息源，定时归档后发送到自己的邮箱，这一波转换，让我可以在邮箱里把自己的信息都阅读完毕，这个工具到现在也还在用，后续看看自己有没有其他的需求再往上加。\n其实做的这些种种，可能还是有点想要创业的心。说创业其实感觉有点重，先不说自己有没有这个能力，自己是不求做的规模多大，只想服务好自己能服务的一部分人，不管是实体还是数字，只要能给他人提供便利或者价值，应该就有人买单，自己从中获取一些利益就好。\n其他 摄影📷 今年用大部分都在用24-105GF4这颗变焦镜头，变焦镜头确实很方便，但是也让我少了很多对视角，透视关系的思考。\n新的一年要多使用定焦镜头，也会多进行思考：如何选择好的视角、如何才能拍的和手机不一样。\n计划是以作品集的方式，拍一个系列的照片，比如日落，云朵，夕阳，下班路上等等。\n画画✏️/3D建模🔨 没想到吧，关于画画和3D建模，自己也很感兴趣，新的一年有时间的话好好看一看，学习学习\n做饭🍳 今年在疫情的情况下，也是没有办法，真正的开始了自己做饭的日子，还别说，自己弄虽然累，但是还蛮有成就感的，也不会难吃，新的一年要继续保持，考虑做一个菜鸟菜谱出来\n旅游🎉 疫情放开了，终于可以安心的出去旅游了，打算看看云南吧，不过这个来年再计划也行，不着急。\nFlag✨ 2023也给自己立一些flag吧\n摄影技术的提升 拍几组作品（成体系的） 用好35MM和85MM的镜头，不要拍出来和现在是一样的 锻炼身体：年底本来已经开始了，结果被放开的疫情打倒了 读更多的书（科幻，经济，技术），同时在多平台做输出（即刻，小红书） 寻找职业上的道路，是让美团还是饿了么拥有我呢 涉猎一些3D建模和画画 好了，可以了，有点多了\n","date":"2022-12-31","permalink":"https://kazma233.github.io/posts/2022-12/2022%E6%80%BB%E7%BB%93/","tags":["年度总结"],"title":"2022总结"},{"content":"概览 关于创业 乌鲁木齐11.24大火导致10人死亡，大量民众上街游行示威 打算减少RSS的使用，转而使用邮件 关于创业 自己一开始是在即刻上关注了一个人，她每天都会发一下创业的感想，我觉得比较有意思，就关注了（输出有“价值”的内容，吸引流量）\n后面发现她有自己的微信群，打算加进去看看（转化流量）\n发现群里在对内部人员搞优惠，最后发现其实也不便宜（变现）\n这一整个流程下，确实也给了我一些创业的思路，也符合自己服务一小部份人的观念，就先待着，看看对方会不会有程序方面合作的需求\n白纸革命 悼念乌鲁木齐逝者，反抗疫情政策。各地掀起游行活动\n從負到零的中國抗議：如果轉折點沒有來，是因為現在才是開始\nRSS 自己一直以来都是RSS的爱好党，但是自从订阅了Newsletter之后，读newsletter的时间反倒比读RSS内容的时间多了，思考了一下，大概总结了以下几个原因：\nnewsletter是邮件主动推送形式的，能够提醒我阅读信息。当然我不是邮件一看到马上就回去把内容看完，而是会记起来，晚上找时间看掉 RSS订阅的比较杂，内容量也比较大，没有好好的管理，大大降低了阅读的兴趣 现在的问题是有些网站仅有RSS提供服务，不提供邮件订阅，我就在想自己写一个RSS2Mail的服务，定时拉取RSS，每晚汇总发送邮件，后面使用起来看看\n处理不确定性的思维 读Shyrism.News这段：不确定的思维：大脑如何处理未知事物，让我了解到了不确定性矩阵（也称作：拉姆斯菲尔德矩阵），他是可以帮助人们在面对不确定情况下做出决策的工具。这个矩阵由四个象限组成，用于表示不同类型的不确定性，下面是原文内容：\n「已知-已知」是我们已知的不确定性，可以针对这些不确定性进行规划。例如，如果我们知道我们公司裁员的可能性很大，我们可以制定一个计划如何处理。 「已知-未知」是我们知道存在的不确定性，但没有足够的知识来制定计划。例如，我们可能不知道公司将来是否会被其他公司收购。或者，你可能意识到离职去自主创业的内在不确定性，但由于还没有足够的数据，无法制定分步计划。 「未知-已知」是我们不知道但默认理解的不确定性，这可能会导致我们在决策中产生偏见和假设。（隐藏的事实） 「未知-未知」是我们不知道的不确定性。例如，一项新技术的开发可能会使我们的产品过时。「未知的未知是指因意外情况而未被考虑的情况所带来的风险。」 对于不同象限的事情，采取的策略是不一样的，大致总结就是想办法先区分该事情的象限，然后想办法把未知的转换成已知的，同时已知的要想办法利用数据来证明，当然最后要清楚的是，你肯定没有办法把所有的未知转化为已知\n工具和服务 开发人员速查表 voce.chat：支持自托管的聊天服务 dub：开源短链服务 Java虚拟机参数表：https://chriswhocodes.com/vm-options-explorer.html 竹白专栏检索：https://zb.liey.cn 值得一读 #25 悲伤旅程：https://shyrz.zhubai.love/posts/2208153012437037056\n封控抗議潮：https://theinitium.com/channel/mainland-zero-covid-protest/\n2022年11月24日，新疆烏魯木齊一封控小區發生火災，因救援不及時最終導致十人身亡。11月25日起，中國烏魯木齊、上海等地民眾及多所高校學生開始自發上街悼念，並抗議延續多時的「清零」封控。\n烏魯木齊一把火延燒全中國 北京清華、南京傳媒學院爆「白紙革命」：https://tw.news.yahoo.com/烏魯木齊-把火延燒全中國-北京清華-南京傳媒學院爆-白紙革命-103720950.html\n","date":"2022-12-04","permalink":"https://kazma233.github.io/posts/2022-12/20221204/","tags":["创业","游行","阅读输入","不确定性矩阵"],"title":"🐾创业、游行、阅读输入、不确定性矩阵"},{"content":"概览 最近在看经济相关的内容，写一些自己得到的看法。\n可以往工业互联网（工业软件）、信息安全、碳中和（碳账本(蚂蚁能量？)，电网）、AR/VR、人工智能这些块看看有没有新的路子。\n数字经济 数字经济是继农业经济、工业经济之后的主要经济形态，数字化转型正在驱动生产方式、生活方式和治理方式发生深刻变革，对世界经济、政治和科技格局产生深远影响。当今世界，发展数字经济已经成为全国共识，是各国的共同机遇。\n数字产业化 《数字经济分类》中的数字产品制造业、数字产品服务业、数字技术应用业、数字要素驱动业4大类为数字产业化部分，即信息通信产业，是数字经济核心产业，为数字经济发展提供数字技术、产品、服务、基础设施和解决方案等。\n简单来说，数字产业化就是把信息的生产以及使用规模化，包括但不限于5G、集成电路、软件、人工智能、大数据、云计算、区块链等技术、产业及服务。\n产业数字化 数字化效率提升业为产业数字化部分，是指应用数字技术和数据资源为传统产业带来的产出增加和效率提升，其新增产出是数字经济的重要组成部分，是数字技术与实体经济的融合。该部分涵盖工业互联网、智慧农业、智能制造、智能交通、智慧物流、数字金融、数字商贸、数字社会、数字政府等数字化应用场景。\n实施 构建系统的促进发展的体制与机制 构建超部门、跨部门的数字化管理机构 当前来看，数字产业还没有部门能够引领和管理 发挥数字技术在各专业行业组织的作用 数字技术包含了各种不同形式的行业组织，切实加强数字产业各子行业组织的作用，发挥其信息传播作用，通过构建对整个行业组织的有效管理，达到构建系统高效的数字产业企业的管理体制和机制的目的 总结起来就是将数字化给铺开，同时给企业降本增效大概吧。一轮经济波动下来，经济下行，现在的企业都不是开始无序扩张了，而是开始寻找一些更加高效工作的方法，往数字化转型。这也就是继农业经济、工业经济之后的主要经济形态：数字经济。数字经济从“产业数字化”，“数字产业化”确定了数字经济的基本范围。\n下午犯困没精神，咋办？ 读happy xiao的newslatter时，看到一个观点：\n“午餐是一个因素，尽量不要在午餐时吃太多或吃太油腻的东西，因为你的身体会将能量转移到消化。此外，尽量在一天之中到外面的新鲜空气中去充实一下。一天中15-20分钟的休息是最起码的。你应该试着离开电脑达一个小时（也尽量避免在电话上冲浪或社交，但与人真正交谈也是可以的）。”\n对于我自己，总结起来就是：\n中午不要吃太饱，不要吃油腻的东西 中午不要看pad了，稍微走走，好好休息一下 下午整点轻松愉快的 复旦教授兰小欢闭门会 之前读了兰小欢的《置身事内》，觉得还不错。\nsource\n值得一读 什么是数字产业化和产业数字化？ - 企企通SRM的回答 - 知乎 暴雪背刺网易，魔兽“后妈”难寻 Go Style Guide Domain-Driven Design (DDD) GitHub 前 CTO：全面微服务是最大的架构错误！网友：这不是刚改完 GitHub 吗 最近很多关于微服务的讨论，发生了什么？ 值得关注 Evernote被收购 zlibrary创始人被逮捕 四年又四年，苹果搜索引擎要“胎死腹中”？ 好早听说过，结果要亡了 日本政府官方设计系统 Notion AI 工具和网站 gorse：使用go语言编写的推荐系统，可以通过物品热门度、人们喜欢的程度、物品相似度，用户相似度、或者协同过滤的方式进行推荐。但是没有懂是怎么实现的。 golang-lru：固定大小的，线程安全的基于内存的LRU缓存框架 HyperUI：开源的css组件库 ","date":"2022-11-19","permalink":"https://kazma233.github.io/posts/2022-11/20221119/","tags":["数字经济"],"title":"🐾数字经济"},{"content":"概览 最近最让自己关注的是“文生图”的一个方向，你用文字描绘一个场景，AI自动帮你生成出你所描述的场景图片。想想是不是很带劲。比较想知道的是目前的应用场景是什么，是否有应用了。\nAIGC：AI生产内容 在这里先整理一下相关内容，打算多看一些相关信息，下面的连接都可以点击，可以直达demo或者注册页面进去玩一玩\n关于数据集：一般认为千亿级的数据就足够了，再多边际效应就过于明显。\n看了相关服务商提供的内容，大概了解了一些可行的应用方向：自媒体文章头条图和封面、海报广告、漫画、视频剪辑等场景\n国外有两家做偏底层数据模型相关内容的组织：\nOpenAI：DALL·E 2 demos Stability: dreamstudio carefree-creator novelai google的文转图：imagen disco-diffusion DALL-E Mini 国内也有做基础数据的，比如：\n北京智源人工智能研究院 在上游的应用层有\nmidjourney showcase 百度-文心一格 6pen 可选不同的模型，比如Stable Diffusion，自研的南瓜模型 滴墨社区（注意无Web版本） zmo 另外还有文字生成相关：\nGPT3 Jasper Copy.ai google的文字生成工具:LaMDA 目前玩了dreamstudio，感觉生成速度还可以，但是可用的图片很少，试了接近20张， 也就看到了一张能直接拿来用的，最近也看到有相关职业对文转图的图片进行调整的职位，也是很神奇。\n空气炸锅 在网络的大力轰炸和吸引下，看到别人随便人手一个美食，不把自己看馋了，还手痒，就也入手了一个空气炸锅\n看原理就是上方有一根热管，再上面有一个风扇，用风扇使热量在内部循环起来，然后煮熟食物\n目前用了两次，烤了红薯和生蚝，感觉还不错，继续倒腾倒腾\n工具或者软件 nicheless：有点像是长文版推特，但是移除了各种喜欢，阅读数量，喜欢数量等相关状态 privacytools：在意隐私？试试这些工具 colima：Container runtimes on macOS (and Linux) with minimal setup Porter：Package your application, client tools, configuration, and deployment logic into an installer that you can distribute and run with a single command. koodo-reader：电子书阅读器，支持网盘同步和文本高亮等功能 realtime：What\u0026rsquo;s happening right now? 值得一读 云南咖啡豆，困在香精里 从 UGC 到 AIGC：穿越历史周期，做时间的朋友 突然爆火的AIGC究竟是不是泡沫？ Musk 接管 Twitter 后，Tumblr 宣布 解除对用户发布裸露内容的限制。 AI都会画画了，老板还会要我吗？ 谷歌推出 KataOS 开源操作系统，基于 Rust 编写 ","date":"2022-11-05","permalink":"https://kazma233.github.io/posts/2022-11/20221105/","tags":["AIGC"],"title":"🐾AIGC"},{"content":"概览 最近想要自己写点东西的想法越来越强烈了，看过了这么多的项目和文章，让我觉得自己创造些什么才是最酷的。\n最近看了一些支持异步io的java框架，打算看看：quarkus，vertx，Spring reactive\n工具和网站 用一个具体的需求讲述linux的某个命令行命令 新类型的迷宫游戏，可以试试看，在浏览器上就能玩 figr：文档加上计算器。有点像是苹果的swift的playground或者python的Jupyter decipad：像是使用数字来协作，算是协作的另一个细分领域吗？还没用上，加到wishlist里了 中文博客榜 reverb：配色生成器 rocket.chat：开源的聊天工具，包含界面和服务端 大事件 Nvidia发布40系新显卡 推荐阅读 Youtube的推荐功能，点了“不喜欢”按钮好像也没有用的另一种说法 平台的处理不透明 平台认为用户的“不喜欢”其实不那么重要 为什么域名有时以.结尾？ 在查找DNS时，最后如果没有.，会在最后的.加上域名(zone files) 使用curl等软件时，加上.表示不使用搜索域(search domains) 为什么使用？它可以100%的表示你不想在后面添加其他东西（在Kubernetes里都有用到） 什么时候使用？在配置DNS使用OK，但在浏览器上NO ","date":"2022-09-25","permalink":"https://kazma233.github.io/posts/2022-09/newsletter2022-09-25/","tags":["newsletter","无想法"],"title":"🐾无标题"},{"content":"概览 这周巨忙，同时周末去爬山去了，导致写newsletter的时间少了，这次就摘抄一些观点和看到的有意思的新闻，文章吧\n观点 不怪老鼠\n如果你已经知道自己的行为会导致什么后果（第一次可能因为无知而吃亏），该负起责任的，不再是对方，不再是人性和本能，不再是我们存在的世界。而是可以选择是否保护好奶酪的，你自己。\n做一个T型人才\n模糊化掉自己的标签，应该具备快速学习和落地的能力，作为开发，也可以考虑产品特性，UI交互等，做一个T型人才（多方涉猎，并专精于某一领域）\n怎么写出很棒的博客文章\n一篇博客应该解决一个问题 标题是灵魂：你要写什么，让读者知道你要说什么 第一句话的任务：让读者不要关掉你的文章 结构是英雄的旅程 人们喜欢列表 你应该写自己的故事 告诉读者怎么做 新闻 Adobe收购Figma\n一个很搞笑的视频\n好玩的 Penpot：开源的Figma，github地址\nImmich：高性能的自托管的照片和视频备份解决方案\nnginxproxymanager：nginx的可视化管理界面\npocketbase：由Go作为后端，内置SQLite的服务，支持简单的REST API和Admin dashboard，内置的文件和用户管理\n自己还没想到应用场景\napipost：基于协作，不止于文档、调试、Mock\nAdobe Color：色轮，调色盘\nbunny fonts：开源的，隐私第一的web字体平台。可以替换google fonts\nmjml：编写响应式布局的电子邮件\n能不能好好说话？：拼音首字母缩写翻译工具\nOpen Source Software Insight：开源项目洞察\ninfinite：用于开发交互式 CLI(tui,terminal) 程序的组件库\n值得一读 Tauri VS. Electron - Real world application\n对比了最近比较热门的两个用于编写桌面应用的框架\n害怕失业的中年人，疯狂学起新技能\n少数派们都得过啥病？谈谈编辑部面对的健康问题\n","date":"2022-09-18","permalink":"https://kazma233.github.io/posts/2022-09/newsletter2022-09-18/","tags":["newsletter","T型人才","写作"],"title":"🐾T型人才、写出很棒的博客"},{"content":"概览 最近发布会频繁，稍微聊一聊，同时也看到Bitwarden的融资消息，最后是关于自己规划的一些内容\n密码 最近看到这篇文章，Bitwarden融资了1亿美元，看到后我是很开心的，这意味着我在使用的密码管理工具有资金来做更多的事情了。这也意味着使用密码工具是一件正确的事\n如果你还不清楚什么是密码管理工具，可以去了解一下Bitwarden，同时忘掉你那不安全的全平台统一的密码，尝试在每一个网站使用不同的密码吧\n同时Bitwarden的项目是一个开源项目，你也可以选择自己搭建服务器，自己托管自己的密码\n使用日历看板规划事项 自己一直在寻找一个适合自己的在工作环境下的Todo list，在经过这一个多月稳定的用下来之后，我想我应该是找到了，那就是FlowUs 息流的日历视图模块：\n使用上我只要在哪一天有要做的事情，那么在对应的日期写上就好了\n我会在任务的前面加上[x]和[ ]两种标识表示任务是否完成的状态（目的是如果以后如果有更好用的工具，方便做迁移）\n同时这个模块是支持自定义属性的，我加了那么一些（分类正在考虑是否移除）：\n不过现在也遇到一些问题，在新建一个事项的时候，实在是太卡了（打一个符号卡1s），希望随着版本迭代，这现问题可以慢慢被修复好（已经上报了问题）\n然后说一下，为什么这个日历模块就是我想要找的Todo list：\n琐事过多：现在工作上基本每天都会有那么一些临时事情找上你，这些事情不是那么紧急（或者无法一下子解决），如果当时自己在写一个逻辑，怕被打断的话，那么我就会在日历的当天日期上记录这个问题，在当前事情告一段落的时候，去看一眼这个日历看板，再去做完就好。另外当天要是有多个事情，也能列一下轻重缓急，分优先级去做 汇报工作：我们每天都会有早晚站会，会上需要说出当天工作内容以及明天的规划，有些比较琐碎的也要说说。按以往的情况，会经常记不住自己昨天做了哪些具体工作（如果一整天都在做某个需求开发就还好），琐事实在太多了。当我有了日历看板我就能有更加清晰的描述我所做的事情了 驱动自己：最后一点也是最重要的一点就是可以驱动自己去完成事情，我自己很享受把这些事情都打上完成标签的感觉，看着自己一天的工作都被完成，成就感满满。这样其实是助长了我做事情的热情，也是提高了自己的工作效率 最后如果你正在发愁找不到一款好的Todo list；或者当前琐事太多，整天焦头烂额的话，不妨试试这个方案吧，支持日历模块的笔记现在有很多了(Notion，Wolai，印象笔记，语雀)，找一个开始用起来吧\n数码发布周 对于爱好者来说真的狂喜，同时有大量的数码产品发布，多到有点电子产品中暑的感觉了\nApple发布会 苹果的发布会看下来，作为手持iPhone13 Pro的用户，对于iPhone14，一点想买的冲动都没有，除了有点想要拥有灵动岛的功能，哈哈\n比较吸引我的还是新款的AirPods Pro 2代，在所有的TWS耳机里，AirPods Pro是我戴着最舒服的了。这次新版用上了新的H2芯片，在降噪有更好的表现，现在的1代说实话降噪是差点意思了\n然后就是期待13号的iOS16了，我必将以我最快速的速度装上iOS16，把我的锁屏界面“美化”一番\n哈苏 哈苏发布了全新的中画幅相机X2D，看Links的视频，哈苏色彩真的很神，虽然价格也是无人能敌。\n当然了，这个价位都是为了追求极致愿意花费大价钱的人，我作为业余爱好者就看看热闹啦\n最近好玩的 又到了最近好玩的模块，看看有哪些好玩的项目吧\n使用markdown写时间线 使用文字，图片，emoji，视频等通过锚点创造动画的web工具，还可以配乐 web版音频编辑器 自托管书签服务 AI个人助理，当前拥有的技能 零开销的JSON日志框架，看起来像是师承zaplog 实时的在web浏览器上看到GO当前运行的指标数据 Generic PriorityQueues, Queues, Stacks, and Deque data structures for Go 数据库建模工具 值得一读 对峙数年后，微软对 Java 的态度 180°大反转 奇葩事儿：删除用户云数据还无法恢复，只赔3万；微信键盘来了，体积524MB；谷歌希望将效率提高20%：暗示将裁员？ | Q资讯 微信键盘 知乎盲水印：v2ex Go语言当前最大挑战：错误处理 基本常识｜为众人烤面包的巴黎贝甜被罚58万，是谁的责任？ Everything 更新服务疑被劫持 Go语言漏洞管理 语句摘抄 Jiayuan\n我把写作当成一种清空大脑的方式，Julia Cameron 发明了一个词：Spiritual Windshield Wipers（精神雨刮器）。\n把每天的焦虑、不安、担心等负面情绪写下来，从而可以以一个清晰的大脑来专注当下。\n这是 CBT（认知行为疗法）中非常重要的一环，在写下来的过程中可以帮助纠正认知扭曲\n新一.enp1s1\n今天学到了解决性能问题是有方法论的，遇到性能问题第一件就是先按照下面表格依次先检查一遍\n此表出自《性能之巅》\n往期传送门\n","date":"2022-09-11","permalink":"https://kazma233.github.io/posts/2022-09/newsletter2022-09-11/","tags":["newsletter","数码产品发布周","关于密码","规划"],"title":"🐾数码产品发布周、关于密码、规划"},{"content":"概览 这周忙一些，不想再去看一些文字信息了（newsletter读的也少了），所以空闲时间都是在通勤的路上，这样听的播客比较多，不过这周听的播客都感觉很有意思，我选一些有意思的话题来聊一聊\n搜索引擎 当你遇到一个不清楚，不了解的问题，你一般会怎么解决呢？对于我来说，我当然是访问谷歌，然后把问题描述贴到搜索栏，之后在搜索结果翻翻，找到想要的答案\n当然，也有和我不一样的人，他们会给出一些不一样的答案。比如如果是比较生活相关的话题：“情侣纪念日怎么过”、“某款包包评价怎么样”等等，他们会去到小红书上，使用小红书的内置搜索功能来找到答案，搜索结果往往也会更加准确\n想想看，这其实是一个比较垂直的场景，在某个垂直服务里使用他们提供给的搜索功能，能够得到更加符合想法的结果，也是一种解决问题的方式\n你觉得这样是好的吗？你喜欢在一个地方解决所有问题，还是“专事专办”呢？我也是在听了这期播客后才意识到，自己也有在特定平台去搜索特定问题的习惯了\n刚才说到的一些垂直领域内容，其实搜索引擎是不想，或者说是没有办法一一覆盖到，因为现在很多服务都是没有网页版的，比如小红书，咸鱼等等，这样搜索引擎也没有办法索引到相关的内容，就加大了搜索引擎在这方面的处理难度。这也是导致“信息孤岛”形成的一个原因。\n怠倦社会 不成功就是因为你不够努力这种毒鸡汤还是算了\n网络上大家都想要分享自己好的一面，所以你看起来大家都是好的\n你积极回应一切的时候，其实是你对一切都没有了防御，回到了原始状态，没有思考的时间\n不要因为一些及时性的诱惑而去做出立即的反应，一旦你回应每一个刺激，每一个反馈，这其实是一种倒退，这会让我们感到很疲惫，很衰竭。生存成了躁动不安，过度反应的一种社会\n现在整个世界都在向你传播着一种你只要努力就会成功的观点，让我们过于积极。但实际上你在网络上接触到的、看到的，往往都是别人展示的好的一面，我们还是要去好好的思考，自己生活的目的是什么\n尝试给自己按下暂停键，给自己一些空白的时间。如果没有这些时间，你就不能好好的反省自己，同时也不能好好的倾听别人，更甚至缺失掉创造的能力\n进步并不是说你不能停下来，你可以而且完全需要停下来，而是不要为了一些无所谓的事情焦虑和内耗\n培育钻石 最近了解了一下关于培育钻石的话题，全世界的培育钻石，有4/9（400/900w）的生产在我国河南，上半年国内培育钻石行业的企业环比均实现了100%的增长\n钻石本来只是石头，是怎么变成现在的真爱，永恒的代名词呢，那就得从戴比尔斯公司开始讲起了\n钻石卖本来就是容易保存，而且售价高昂，这些特性都给新钻石的销量增长带来了困难，这时戴比尔斯公司就找到了广告公司，计划从文化价值方向对钻石进行重新的包装\n他们通过电视明星，电视台等到处讲述着关于钻石的浪漫故事，向人们灌输钻石在人们婚礼中的地位，这也让钻石有了“钻石恒久远，一颗永流传”的代名词。在这种时候，钻石已经从一种物质消费变成了精神消费\n在培育钻石占有率开始攀升的情况下，还推出过“真的才是稀有的，真正的才是钻石”广告词，来强调天然钻才是真钻石\n然而培育钻实际上和天然钻一样，都是真正的钻石。而且培育钻石更加纯净，更加现代，钻石质量也更加的可控，反而天然钻在开采时对当地生态造成了很大的影响，当地的百姓也很少从钻石贸易中获益，所以天然钻还被称为“吸血钻”\n到了现在，培育钻石在推介的时候更多的使用：“自由，独立，美”等代言词，鼓励男女消费者随时随地，想买就买。虽然培育钻给天然钻造成了一定的冲击，当然现在仍然有不少人看重天然钻，他们认为钻石属于炫耀性消费，它的产地、价格、品牌才是最重要的\n所以问问你，你会在什么情况下购买钻石，计划购买什么样的钻石呢？（不买）\n最近好玩的 tauri 构建跨平台的快速、安全、前端隔离应用 apache shenyu Java 原生API网关,用于服务代理、协议转换和API治理 genact 让你的电脑看起来很忙，让你看起来是在真正的工作，而不是在摸鱼 heptabase 笔记工具，特点是在一个界面能看到所有的笔记和他们的关联关系 zeroG 一款打破旧观念的浏览器，网页并不是只能通过tab来区分展示，也可以在一张无线的画布摆放 favicon favicon生成。可以通过png，text，emoji来生成favicon linegraphmaker 各种图表生成工具，支持直线图，饼图，柱状图等等 quickref 命令快速参考，支持Bash，Vim，正则等等，没事当个手册上去翻翻 自托管 vikunja TODO list 自托管服务，我自己写了一个docker-compose可以快速上手 GoGallery 为大型照片集设计的静态网站生成器。你只需要提供一个存放图片的文件夹，剩下的交给这个工具帮你生成你的作品网站 RustDesk 以前折腾过使用frp搭建中间服务，使得RDP可以跨越互联网，而不仅仅是局域网来使用。RustDesk就是RDP+frp，你可以使用它自己的服务进行远程连接另一台设备（不仅仅是电脑），也可以自建服务，这样你可以一个人享受带宽的速度，带来更好的体验。而且是开源的项目，爱了爱了。 ","date":"2022-09-03","permalink":"https://kazma233.github.io/posts/2022-09/newsletter2022-09-03/","tags":["newsletter","搜索引擎","倦怠社会","人工培育钻石"],"title":"🐾搜索引擎、倦怠社会、人工培育钻石"},{"content":"概览 最近听了关于网络暴力的播客，听机核闲聊关于熬夜和拖延症\n高温 最近高温，干旱持续，从一开始的热射病，到四川限电，均表现出了今年的高温和往常的不一样。\n看到四川限电，从这篇文章新能源搞了这么久，为什么缺电更严重？了解到，四川的主要电力来源都是水电，往年水量丰盈的时候还能往外输送电力，今年怕是要变成购电户了,同时高温对于太阳能发电也有影响，温度太高，会导致光伏电站运转更差。另外可以通过全国电力区域版图，谁挑大梁？这篇文章了解一下我国电力的区域版图，给我印象最深的是内蒙古的发电量(5952.6亿千瓦时)那么大，用的那么少(剩余1995亿千瓦时)，同时广东发电量(6115.2亿千瓦时)也很大，不过使用电量更大(剩余-1751.8亿千瓦时)，内蒙古可凭一家之力，补上广东的用电缺口，妥妥的西电东送。\n熬夜和拖延症 熬夜真的是熬夜一时爽，一直熬夜一直爽\n听机核的最新一期《核市奇谭Vol.44》，说到熬夜的坏处比如头昏脑胀、注意力不集中等现象，还可能出现头疼，长时间可导致记忆力下降等。甚至后续想要恢复正常作息都比较困难，会导致想睡睡不着，建议还是早睡早起，早晨的空间也能让人神清气爽。\n审视了一下自己，发现自己的睡眠时间有点太短了，看健康APP每天才睡（甚至不足）6个小时。虽然之前有立flag每天早起，早期是做到了，但是睡得却是越来越晚了。看起来对自己好像没有什么影响，但是就是怕造成的影响已经被自主忽略了，所以还是在这里再立一个flag吧，必须早睡早起，拜托拖延症。\n网络暴力 对于事情本生，大家会更加关注到被网暴的人身上。给与一些标签（甚至捏造一些标签），站在道德的制高点进行批评\n网络匿名性更加能够激发人性幽暗\n在网络这个匿名的背景中，人内心深处的种种幽暗的情绪都会被释放，人们会特别的习惯于好变，会放纵自己好变的天性，也会释放自己无知的热情\n这对于平台来说需要完善相关的审核制度（机器+人工），同时把网暴重视起来，塑造更友善的讨论环境。\n站在我们自己的立场，在强调结构性的问题上，我们也有释放自己的善意的权益，为什么要去释放自己的恶意呢，你有自己的选择权。\n这个世界是由我们共同创造的。\n最近好玩的 你来设计下一台iPhone Google函数计算服务2nd进入GA 阿里云函数计算 每月前100万次函数调用免费 谷歌Cloud Functions 每个月200w次免费调用 tailwindhelper 通过一些按钮选项的选择，快速生成CSS和HTML gradientify 漂亮的渐变色生成 ","date":"2022-08-27","permalink":"https://kazma233.github.io/posts/2022-08/newsletter2022-08-27/","tags":["newsletter","高温","网络暴力","拖延症"],"title":"🐾newsletter，高温，网络暴力，拖延症"},{"content":"概述 最近打算开始写Newsletter了，自己很喜欢这种获取信息和交流的方式，就顺手整理以下自己获取信息的方式和渠道，会不定时更新\n2022-12-25：更新 2023-06-29: 亟待更新ing RSS RSS目前看的比较多的是一些独立的博客网站，还有是一些科技媒体。\n最近不是也喜欢上了看newsletter，想收束以下阅读的入口，别RSS，邮箱客户端两头跑，就自己写了个程序定时拉取RSS信息，在早中晚定时推送RSS信息到我的邮箱，还挺好用。预览放在文章后面\n动点科技 爱范儿 虎嗅 钛媒体 Spring-All Posts Hacker News 月光博客 少数派 超能网 品玩 数字尾巴 Android Authority 酷壳 阮一峰的个人网站(ProxyNeed) 极客公园 程序员的喵 美团技术团队 鸟窝 videocardz Newsletter 自己真的很喜欢捣鼓工具和一些自托管的服务，莫名的热爱。也喜欢看别人聊关于科技、生活、职场、社会、游戏等等话题\nbestxtools 发现并分享有趣，有创意，免费、好用的工具，每周四发布 weichen 成功只是手段，好好生活才是目的。设计一个更健康、更富足、更明智和更有趣的生活 好好生活，好好思考 densediscovery 一篇有思想的周报，帮助你感受灵感，提高生产力和批判性思维 noted 关于可以自托管服务的newsletter Design Scenes Weekly 设计视角下的互联网资讯观察与节选 暂时停更了 搜信源 订阅地址 聊一些最近的热点，大事件 Steve说每周通讯 一般聊一些互联网的新闻，和一些生活事件 workspaces “拍桌子”，看看别人（创意工作者）的工作环境 selfhosted 最热门的关于自托管服务的文章和项目，每周一封。 网站底下还有关于Java、Go特定编程语言的newsletter可以订阅，可以去看看 新闻实验室 新闻实验室文字版 可乐周报 关于效率，生活，和思维方式 golangweekly 关于Golang的新闻，每周一封。还会推荐一些Golang的框架 Rust updates 每周一封，关于Rust producthunt bytebytego 阮一峰的网络日志 财新网主编精选 结绳志 生活奇旅 播客 基本上在早上和晚上听，度过无聊的通勤时间，偶尔听到有意思的也会坐着慢慢听\n声动早咖啡 每周一三五讲一些科技资讯 美妆柜台后的大并购：雅诗兰黛为什么想要收购 Tom Ford？ 无人知晓 当初听组织进化论的时候，听的就是和无人知晓聊《孟岩：最好的投资，是投资自己》 这是一档投资向对话类播客，也是经常邀请人来做客 姐姐说 聚焦女性多元生活方式和状态的播客 听Ep.47 这是一个出生就被宣判死亡的故事这集入坑的 三五环 邀请播主的朋友聊一些播主喜欢的内容，大部分都是产品、品牌相关 三五杯茶联合创始人，很喜欢一个观点：服务好一小部分人 组织进化论 职场话题和企业管理 捕蛇者说 聊聊编程、程序员和 Python 牛油果烤面包 大部分时间在聊科技，聊数码，聊产品，很对胃口 奇想驿 做了一个产品：flomo 同时还在写产品沉思录，内容精选 新闻实验室 讲述传媒和科技相关话题，自己很喜欢播主的思想和观念，符合我自己的价值观念。 最近在听：一名网暴受害者的讲述与思考｜新闻实验室28 日谈公园 畅聊电影音乐文学动漫热门作品，分享旅行美食消费时尚生活方式 Anyway.FM设计杂谈 设计杂谈。除了设计，什么都谈（玩笑） 最近在听当我们聊工具时我们在聊什么 机核 主说游戏的播客，说说游戏内容，游戏设计，游戏背景故事，书籍推荐等等。一群人超有意思，推荐收听 同时有自己的网站，可以在上面看一些游戏生活资讯，还有游戏周边，有声书可以购买 社交媒体 这边最近翻的比较少了，一个是时间问题，另一个是真的没有那么有兴趣社交了\nTelegram（一款IM工具） 有一些技术人或者有做side project的人会在上面建一些讨论群，自己偶尔上去翻翻看大家的聊天信息 同时还有关注一些游戏，动漫相关的资讯channels v2ex V2EX 是一个关于分享和探索的地方 自己喜欢在上面看别人讨论关于技术/科技/生活/工作的方方面面，用于扩充知识和见闻 segmentfault 纯技术论坛，有问答，文章和课程模块，之前有一段时间很喜欢在上面回答别人的问题 发布过三篇技术文章，后续没有坚持下去，就没发了 掘金 主要是写技术博客的网站，后面加了一些生活和讨论(沸点)的模块 机核 在上面看一些游戏生活资讯，还是听播客比较多 微信公众号 其他 这块主要是阅读财新通\n财新网：买了一年的财新通 界面 新闻网站 服务于独立思考的人群 有自己的编辑团队 澎湃新闻 有自己的编辑团队 IT之家 机核 源看板 依据你喜欢的主题和方向，订阅新闻内容来进行阅读 果壳 feed2mail项目 项目地址\n预览截图(早期) ","date":"2022-08-23","permalink":"https://kazma233.github.io/posts/2022-08/%E6%AF%8F%E5%91%A8%E9%83%BD%E4%BC%9A%E7%9C%8B%E7%9A%84%E5%86%85%E5%AE%B9/","tags":["信息获取"],"title":"🦄分享：我获取信息的方式"},{"content":"前言 最近迷上了摄影，边学边玩也有一段时间了，就想要把三要素给说一说，同时帮助自己查缺补漏。下面开始吧。\n提前的知识 CMOS图像传感器 感光元件是一种将光学影像转换成电子信号的设备，如今，图像传感器主要分为感光耦合元件（charge-coupled device, CCD）和互补式金属氧化物半导体有源像素传感器（CMOS Active pixel sensor）两种\n现在相机的感光元件大部分都是CMOS感光元件\n来源\n而我们平时说的相机CMOS指的就是这个CMOS感光元件，平时看到的图像也是光线照射到CMOS转换成数字信号，经由CPU处理才从屏幕上看到\n三要素 这篇文章我想聊的就是摄影的三要素光圈，快门，ISO，这些参数关系到你能不能拍到一张你想要的照片，算是编程里的基础语法。\n光圈 光圈是镜头里用来控制镜头孔径大小的部件，它和快门协同工作控制进光量。\n看下面这张图，这是镜头开了不同大小光圈的样子，其中一般用F来表示光圈，后面的数值表示光圈大小，具体定义参考维基百科 由KoeppiK - 自己的作品，CC BY-SA 3.0\n可以看图得到一些结论：\nF数值越小，光圈越大 光圈由光圈页片控制大小 光圈越大，镜头经过的光线越多，拍到的画面就会越亮 同时光圈还控制着一些其他的东西，看下面两幅图片： 其中图一是在光圈值开到F1.4（大光圈）的时候的画面，第二张是光圈开到F8（小光圈）时候的画面，发现了什么？他们的背景清晰度不一样，光圈大给人看到的就是主体实，背景虚。\n所以光圈还影响背景的虚化效果，这个叫做景深，后续会再继续讲。\n快门 快门是相机里用来控制光线照射在感光元件上时间长短的装置\n看下图，快门是用秒作为单位，在不同的快门速度下，拍摄运动的物体会有不同的效果： 可以认为：快门控制的就是曝光时间的长短\n曝光时间越长，接受的光线也就越多，画面也就越亮 曝光时间很长，如果被摄物体或者相机移动的话，会导致有拖影的现象 像是星轨，车灯涂鸦都是慢快门拍摄：\n溅起水花，雨点一般由快快门拍摄：\n总结起来就是：\n如果你想拍到某个物体一瞬的样子，那么你的快门速度必须要比他的移动，变化速度要快 如果你想要拍摄物体的运动，变化轨迹，那么快门就需要尽可能的慢 感光度（ISO） 数码相机的ISO是通过调整感光元件对光线的灵敏程度或者合并感光点来实现的，也就是说是通过提升感光元件的光线敏感度或者合并几个相邻的像素点来达到提升ISO的目的。\n来源\n用人话来说ISO就是相机对光线的敏感程度，数值越大，对光线越敏感，得到的画面也会越亮，但同时也会把信号的噪声给放大，就会在画面上看到噪点\n不同的相机对ISO提高后的噪点处理能力各不相同，一般A7M3我最多会加到6400，再高我就考虑降低快门速度了（靠铁手）\n快门需要讲解的不多，需要注意的是ISO一般是作为最后的手段才会去使用的，毕竟ISO增高，噪点也就多了\n景深 之前提到了一个景深的概念，可以看下图：\n由Redjar，CC BY-SA 3.0\n三只蝴蝶在前中后的位置，只有在中间的蝴蝶才是清晰的，其他两只蝴蝶从中间到两边越来越模糊，那么中间清楚的这部分就是景深。\n那么还有那些因素会影响景深呢？我列一下：\n光圈 物距 画幅 焦段 详细了解以及来源参考这里\n该怎么使用 先说一下相机上的挡位，这些档位对三要素有着不同的控制方式：\nP档（Programmed Auto）：程序自动模式，用户不需要控制光圈快门，系统会自动计算。 A档（Aperture-priority Mode）：光圈优先模式，部分相机称为Av档，用户可以控制光圈值，系统会自动计算出合适的快门速度，可以用来调整景深，是非常常用的模式。 S档（Shutter-priority Mode）：快门优先模式，部分相机称为Tv档，用户可以控制快门速度，系统会自动计算出合适的光圈。 M档（Manual Mode）：全手动模式，光圈值和快门速度都可以由用户控制。 Auto档：全自动，所有参数皆有相机控制，包括光圈值、快门速度、ISO感光度、闪光灯、白平衡等等。 在不同的场景会使用不同的档位，一般来说A,S,M档应该会用的比较多\n在了解前面的知识后，你可能会有疑问：我应该在什么时候设置什么样的参数，才能拍好照片呢？结合上面的例子，我说一下几种情况参考，在后续拍摄时多尝试，慢慢思考就能熟练运用了。\n高速移动的物体，比如打鸟，连拍等，这种时候肯定是要保证快门速度，那么我们可以用快门优先模式(S)，让相机去控制光圈和ISO 如果我们拍摄唯美的人像，需要有比较好的背景虚化效果，那么我们会想要控制光圈的大小，这时候可以选择光圈优先模式(A)，让相机去控制快门和ISO 当然上面这些并没有解决所有的拍摄问题，有时候你还是会需要M档。你可能会需要手动来控制光圈和快门速度，来保证你需要的效果。比如夜景人像，在需要大光圈的同时，你也不想手持的时候快门太慢，这样照片容易糊，成片率太低，只能定住一个最低的快门速度，然后同时调整ISO来满足需求。\n总结 摄影有很多东西要学，除了这三要素，还有测光，白平衡等；在另一方面构图，光影也是一番大讲究；最后后期的处理也是不能忽略的一大块。虽然有很多要学，感觉前路漫漫，但也正是因为有这么多可学，才很开心。最后，让我们保持住对摄影的热情，多实践，多思考，每天进步一点，一起加油吧。\n","date":"2021-06-29","permalink":"https://kazma233.github.io/posts/2021-06/%E5%85%89%E5%9C%88%E5%BF%AB%E9%97%A8iso/","tags":["摄影"],"title":"光圈，快门，ISO"},{"content":"最近在弄hugo搭博客，涉及到了git的submodule操作，在这里做一个记录，如何正确的操作git的submodule\n移除子模块 To remove a submodule you need to:\nDelete the relevant section from the .gitmodules file. Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config. Run git rm \u0026ndash;cached path_to_submodule (no trailing slash). Run rm -rf .git/modules/path_to_submodule (no trailing slash). Commit git commit -m \u0026ldquo;Removed submodule \u0026quot; Delete the now untracked submodule files rm -rf path_to_submodule I think above can be simplified using following commands:\ngit submodule deinit \u0026lt;path_to_submodule\u0026gt; git rm \u0026lt;path_to_submodule\u0026gt; git commit-m \u0026quot;Removed submodule \u0026quot; rm -rf .git/modules/\u0026lt;path_to_submodule\u0026gt; 删除完后，就可以重新添加submodule了\n克隆项目 克隆包含子模块代码: git clone --recursive [URL to Git repo] 如果已经拉取了代码 git submodule update --init # if there are nested submodules: git submodule update --init --recursive 更新 git submodule update --remote --merge 资料 官网 gist Using submodules in Git - Tutorial ","date":"2021-01-18","permalink":"https://kazma233.github.io/posts/2021-01/git%E7%9A%84submodule%E6%93%8D%E4%BD%9C/","tags":["教程","git"],"title":"git的submodule操作"},{"content":"由于TeamViewer吃相越来越难看，只能自己动手了。使用frp的内网穿透功能来支持。\n前言 frp的项目地址\n这里可以参考使用官方的SSH配置，因为RDP也是用的TCP连接\n原理：使用frp在服务器端进行流量的转发，和代理有点类似\n服务器端配置 以下内容在服务器端操作\n从git上下载对应的压缩包(wget)\n解压，并编辑frps.ini文件，这是frp的服务端配置文件\n[common] bind_port = 7000 token = token # 控制台的用户名 dashboard_user = username # 控制台的密码 dashboard_pwd = passwd # 控制台的端口 dashboard_port = 7100 启动(后台运行考虑用nohup)：frps -c frps.ini\n客户端配置 同样的下载当前操作系统的frp压缩包\n解压，并编辑frpc.ini文件\n[common] server_addr = 服务器ip server_port = 服务器frpcs的bind_port端口 # client的ui admin_addr = 127.0.0.1 admin_port = 7100 admin_user = username admin_pwd = passwd token = token # 启动阶段无网络时一直等待而不是直接退出 login_fail_exit = false [**RDP-Name**] # RDP 是 TCP 协议的 type = tcp # 本机 IP local_ip = 127.0.0.1 # 远程桌面的默认端口 local_port = 3389 # 外网访问的端口，服务器端该端口也需要开启 remote_port = 7001 # 是否加密 use_encryption = true # 是否压缩 use_compression = true 启动命令：frpc -c frpc.ini\n连接 打开RDP远程桌面连接工具（Windows 10自带）\n地址输入：frpc.ini的server_addr+remote_port，并提前输入好用户名，如下图\n之后就可以看到远程电脑的桌面了（后续弹出什么凭证啥的，都保持默认，点击OK就好了）\n后台运行 使用winsw注册成windows的服务（自启，后台运行）\nwinsw/winsw\n先下载对应的exe文件\n这个应用需要有.NETCore框架，那些体积比较大的是自带了.NETCore框架，系统没有.NETCore的可以考虑下载那几个文件\n然后写一个xml的配置文件\n\u0026lt;service\u0026gt; \u0026lt;!-- ID of the service. It should be unique accross the Windows system --\u0026gt; \u0026lt;id\u0026gt;frp\u0026lt;/id\u0026gt; \u0026lt;!-- Display name of the service --\u0026gt; \u0026lt;name\u0026gt;frp\u0026lt;/name\u0026gt; \u0026lt;!-- Service description --\u0026gt; \u0026lt;description\u0026gt;frp client\u0026lt;/description\u0026gt; \u0026lt;!-- 工作目录 --\u0026gt; \u0026lt;workingdirectory\u0026gt;frpc的工作目录\u0026lt;/workingdirectory\u0026gt; \u0026lt;!-- Path to the executable, which should be started --\u0026gt; \u0026lt;executable\u0026gt;frpc\u0026lt;/executable\u0026gt; \u0026lt;!-- exe的参数 --\u0026gt; \u0026lt;arguments\u0026gt;-c frpc.ini\u0026lt;/arguments\u0026gt; \u0026lt;!-- 滚动日志记录 --\u0026gt; \u0026lt;!-- OPTION: log Defines logging mode for logs produced by the executable. Supported modes: * append - Rust update the existing log * none - Do not save executable logs to the disk * reset - Wipe the log files on startup * roll - Roll logs based on size * roll-by-time - Roll logs based on time * rotate - Rotate logs based on size, (8 logs, 10MB each). This mode is deprecated, use \u0026quot;roll\u0026quot; Default mode: append Each mode has different settings. See https://github.com/kohsuke/winsw/blob/master/doc/loggingAndErrorReporting.md for more details --\u0026gt; \u0026lt;log mode=\u0026quot;roll\u0026quot;\u0026gt;\u0026lt;/log\u0026gt; \u0026lt;/service\u0026gt; 把刚才下载的exe文件和刚才编辑的xml文件重命名成相同的名字，后缀不变，比如：frpc-service.exe和frpc-service.xml\n然后执行即可：frpc-service.exe install，弹出授权框，同意即可\n随后在windwos的服务上，能看到该服务\n运行：frpc-service.exe start，启动该服务\n注意事项 客户端需要保证一直启动 网络环境要足够好 有多个客户端时，每一台电脑要有不同的客户端服务名称 wiki 文档 ","date":"2020-07-26","permalink":"https://kazma233.github.io/posts/2020-07/%E8%AE%A9rdp%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E9%9D%9E%E5%B1%80%E5%9F%9F%E7%BD%91%E7%9A%84%E7%94%B5%E8%84%91/","tags":["教程","frp","RDP"],"title":"让RDP远程连接非局域网的电脑"},{"content":"xxl-job的简单入门\n前言 在写这篇文章之前，我们有一个单独的任务调度项目，这个项目按照cron表达式，隔一段时间执行一下项目的API。目前来看如果项目不大的话用这种方式也是挺好的，对项目侵入性低，也很灵活。不过由于这个任务调度项目功能过于简单（没有告警，没有页面可以方便的查看日志，权限管理等），也没有足够的文档。所以我们干脆直接找一个开源的分布式任务调度框架。在对比之后选了xxl-job，看上的是它的轻量和容易上手，而且上述的要求它都能满足。\nxxl-job概念 首先先介绍一些xxl-job的概念：\n调度中心：统一管理任务调度平台上调度任务，负责触发调度执行，并且提供任务管理平台。也就是执行器的触发角色 执行器：执行器就是我们需要执行的任务项目了，它由调度中心来负责调用 调度中心搭建 搭建方式有两种，一种是拉取git仓库的源码(SpringBoot项目)，修改SpringBoot的配置文件打包运行就好了\n我选的另一种搭建方式，使用Docker的方式来搭建，先上docker-compose.yml文件，一看基本上就明白了\nversion: '3.5' services: xxl-job-mysql: image: mysql:8.0 container_name: xxl-job-mysql environment: MYSQL_ROOT_PASSWORD: ${MYSQL_PASS} volumes: - ${VOLUME_PATH}/xxl-job-mysql:/var/lib/mysql - ./xxl-job.sql:/docker-entrypoint-initdb.d/xxl-job.sql restart: always networks: - kazma_net command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci xxl-job: image: xuxueli/xxl-job-admin:2.2.0 container_name: my-xxl-job restart: always ports: - 9010:8080 volumes: - ${VOLUME_PATH}/xxl-job/applogs:/data/applogs networks: - kazma_net environment: TZ: Asia/Shanghai PARAMS: \u0026quot;--spring.datasource.url=jdbc:mysql://xxl-job-mysql:3306/xxl_job \\ --spring.datasource.username=root \\ --spring.datasource.password=pw123456 \\ --spring.mail.host=smtp.163.com \\ --spring.mail.username=kazma_todo@163.com \\ --spring.mail.password=\u0026quot; depends_on: - xxl-job-mysql networks: kazma_net: name: kazma_network 其中xxl-job.sql文件是xxl-job官方的sql，需要初始化数据库设置。放入Docker的docker-entrypoint-initdb.d目录下，该sql文件会自动执行，后续初始化后，就不会再执行了。可以参考我的github配置\n另外environment下的配置也可以参看官方的Dockerfile文件:\nFROM openjdk:8-jre-slim MAINTAINER xuxueli ENV PARAMS=\u0026quot;\u0026quot; ENV TZ=PRC RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone ADD target/xxl-job-admin-*.jar /app.jar ENTRYPOINT [\u0026quot;sh\u0026quot;,\u0026quot;-c\u0026quot;,\u0026quot;java -jar $JAVA_OPTS /app.jar $PARAMS\u0026quot;] 这里把PARAMS的参数传递给了项目，具体参数可以参考官方github上的application.properties文件` TZ是写入到了系统的时区上了 这样访问就可以访问了：http://192.168.1.233:9010/xxl-job-admin，端口是9010，路径是xxl-job-admin，界面如下：\n默认的用户名是: admin 密码是: 123456\n编写执行器 在启动好了调度中心后，会有一个默认的执行器，但是这个只是单纯的配置了，并没实际的代码实现。我们现在就来实现一个，不过我们不会用他这个名字。\n新建SpringBoot项目：\n项目依赖如下：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.xuxueli\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;xxl-job-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 主要是xxl-job-core这个依赖\n项目配置如下：\n我单纯的把官方的配置转换成了yml的格式\nserver: port: 9200 logging: level: root: debug xxl: job: ### 执行器通讯TOKEN [选填]：非空时启用； access-token: admin: ### 调度中心部署跟地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行\u0026quot;执行器心跳注册\u0026quot;和\u0026quot;任务结果回调\u0026quot;；为空则关闭自动注册； addresses: http://192.168.1.233:9010/xxl-job-admin executor: ### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册 appname: demo-job ### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。 address: ### 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 \u0026quot;执行器注册\u0026quot; 和 \u0026quot;调度中心请求并触发任务\u0026quot;； ip: ### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口； port: 9999 ### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径； logpath: ./applogs/xxl-job ### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能； logretentiondays: 30 接下来是初始化xxl-job\nXxlJobConfig.java文件\npackage com.xxljob.config; import com.xxl.job.core.executor.impl.XxlJobSpringExecutor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; @Component @Configuration public class XxlJobConfig { private static final Logger LOGGER = LoggerFactory.getLogger(XxlJobConfig.class); @Value(\u0026quot;${xxl.job.admin.addresses}\u0026quot;) private String adminAddresses; @Value(\u0026quot;${xxl.job.access-token}\u0026quot;) private String accessToken; @Value(\u0026quot;${xxl.job.executor.appname}\u0026quot;) private String appname; @Value(\u0026quot;${xxl.job.executor.address}\u0026quot;) private String address; @Value(\u0026quot;${xxl.job.executor.ip}\u0026quot;) private String ip; @Value(\u0026quot;${xxl.job.executor.port}\u0026quot;) private int port; @Value(\u0026quot;${xxl.job.executor.logpath}\u0026quot;) private String logPath; @Value(\u0026quot;${xxl.job.executor.logretentiondays}\u0026quot;) private int logRetentionDays; @Bean public XxlJobSpringExecutor xxlJobExecutor() { LOGGER.info(\u0026quot;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; xxl-job config init.\u0026quot;); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppname(appname); xxlJobSpringExecutor.setAddress(address); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } } 这里读取了application.yml的配置，初始化了一个XxlJobSpringExecutor对象。\n真正的任务执行器代码\n这其实就是一个service\n@XxlJob(\u0026quot;xxl-job-handler\u0026quot;) public ReturnT\u0026lt;String\u0026gt; execute(String param) { XxlJobLogger.log(\u0026quot;hello world.\u0026quot;); return ReturnT.SUCCESS; } 官方解释，我直接摘抄过来了\n1、在Spring Bean实例中，开发Job方法，方式格式要求为 \u0026quot;public ReturnT\u0026lt;String\u0026gt; execute(String param)\u0026quot;\n2、为Job方法添加注解 \u0026quot;@XxlJob(value=\u0026quot;自定义jobhandler名称\u0026quot;, init = \u0026quot;JobHandler初始化方法\u0026quot;, destroy = \u0026quot;JobHandler销毁方法\u0026quot;)\u0026quot;，注解value值对应的是调度中心新建任务的JobHandler属性的值。\n3、执行日志：需要通过 \u0026quot;XxlJobLogger.log\u0026quot; 打印执行日志；\n以上就是整个项目的代码了，可以启动，并且查看日志。\n2020-05-16 19:43:22.410 DEBUG 51880 --- [rRegistryThread] c.x.j.c.thread.ExecutorRegistryThread : \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; xxl-job registry success, registryParam:RegistryParam{registryGroup='EXECUTOR', registryKey='demo-job', registryValue='http://192.168.1.105:9999/'}, registryResult:ReturnT [code=200, msg=null, content=null] 可以看到本地的任务地址是http://192.168.1.105:9999/，也就是我们配置的xxl-job配置上的，不是SpringBoot项目的9200端口，这个要注意。然后demo-job是执行器的名称\n配置任务调度中心 配置执行器 重新回到xxl-job的任务调度中心web页面，左侧点击执行器管理，新增一个执行器。这里的AppName就是我们代码配置的xxl.job.executor.appname，然后选自动注册就好了。\n任务管理 点击左侧的任务管理，新增一个任务，具体的解释可以看官方文档 然后在当前任务的右侧点击下拉箭头，单机运行一次，可以在执行器项目的控制台上看到日志的输出，并且在任务调度中心的调度日志上也能看到具体的调用日志。\n想要正式的启动，就在任务管理的单个任务上，单机下拉箭头，点击启动即可。后续可以观察日志或者设置告警邮件来检查定时任务的执行过程。\n总结 像是邮件告警，权限控制这些我并没有特意的去说明，因为这些太简单了，在界面上点点就能懂。要是有什么疑问也可以看官方的文档解决。\nxxl-job我们也刚开始用，后续如果有什么优化，或者更进阶的使用，我也会用新的文章写上来，总之会把我们现在的任务调度服务给慢慢替换掉\n人生苦短，保持简单才是一个项目持久的王道\n","date":"2020-05-16","permalink":"https://kazma233.github.io/posts/2020-05/xxl-job%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/","tags":["教程","xxl-job"],"title":"xxl-job入门"},{"content":"这里要介绍的是Spring出的spring-cloud-starter-gateway\n开始 先了解SpringCloud Gateway的相关概念：\nRoute（路由）：路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由； Predicate（断言）：指的是Java 8 的 Function Predicate。 输入类型是Spring框架中的ServerWebExchange。 这使开发人员可以匹配HTTP请求中的所有内容，例如请求头或请求参数。如果请求与断言相匹配，则进行路由； Filter（过滤器）：指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前后对请求进行修改。 作者：MacroZheng 先看看路由的断言有哪些：\nThe After Route Predicate Factory：匹配在指定日期时间之后发生的请求 The Before Route Predicate Factory：匹配在指定日期时间之前发生的请求 The Between Route Predicate Factory：匹配在指定日期时间端之内发生的请求 The Cookie Route Predicate Factory：cookie路由 The Header Route Predicate Factory：header路由 The Host Route Predicate Factory：主机名地址路由 The Method Route Predicate Factory：请求方法路由 The Path Route Predicate Factory：请求uri路由 The Query Route Predicate Factory：请求参数路由 The RemoteAddr Route Predicate Factory：ip请求路由 The Weight Route Predicate Factory：权重路由 路由 了解这些内容后直接看一个示例：\npom.xml先引入依赖(2.2.6.RELEASE和Hoxton.SR3)：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-gateway\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 建议网关的配置都写配置在yml配置文件上，不用java代码写，这样可以更方便的通过配置中心动态修改网关配置\nspring: cloud: gateway: routes: - id: order-service uri: 'http://192.168.1.233:9300' predicates: - Path=/order-service/** routers下面来配置所有的路由规则 id表示一个唯一的值 uri表示路由转发的地址 predicates断言的配置，就是上面那些 这里交代一下：我已经启动了一个order-service监听在9300端口了，这个服务有一个路由是order/create\n这里使用的是Path断言，当请求的路径是/order-service/**(**表示任意内容)时，则把请求转发到http://192.168.1.233:9300即：\nhttp://192.168.203.233:9500/order-service/order/create -\u0026gt; http://192.168.203.233:9300/order-service/order/create 拦截器 SpringCloud Gateway的全部filter都在文档上有，想要概览一遍可以看看官网文档\n前缀分离 现在你应该会发现一个问题，我们uri上的order-servidce只是用来区分请求不同的服务的，真正的请求uri是order/create，怎么转发请求的时候也给带上了这个前缀呢？那么想要解决这个问题的话一起来看看Spring网关自带的filter吧\n想要实现上面的需求，把一个请求的几个前缀给去掉，可以使用The StripPrefix GatewayFilter Factory，这个拦截器很简单，用于剥离请求uri的层级，我们在上方的yml里新增一些配置，感受一下变化：\nspring: cloud: gateway: routes: - id: order-service uri: 'http://192.168.1.233:9300' predicates: - Path=/order-service/** # 新增配置 filters: - StripPrefix=1 我们新增了一个filters配置，这是一个数组\n然后下面我们配置了一个叫StripPrefix的filter，这个就是上面说到的StripPrefix GatewayFilter。设置的值为1，则说明我们会剥离一层的uri，最终的请求转发情况如下：\nhttp://192.168.203.233:9500/order-service/order/create -\u0026gt; http://192.168.203.233:9300/order/create 断路器 这样就完美的达到了我们的要求，是不是很开心，但是这还并没有完哦。\n好好想想，在分布式系统中，网关作为流量的入口，因此会有大量的请求进入网关，向其他服务发起调用，其他服务不可避免的会出现调用失败（超时、异常），超时会造成网关堆积的请求过多，而失败则需要快速返回失败给客户端，想要实现这个要求，就必须在网关上做熔断、降级操作\n这时候该断路器上场了，同样的SpringCloud Gateway也提供了这么一个Spring Cloud CircuitBreaker GatewayFilter Factory拦截器。这个拦截器需要有断路器的实现(impl)来配合，这里用的是SpringCloud新的断路器Resilience4J Circuit Breakers，想要用这个断路器还需要一些新的依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-circuitbreaker-reactor-resilience4j\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 这是circuitbreaker的resilience4j实现\n新增配置：\n自定义一个断路器（可不做）：\n@Configuration public class MyCircuitBreakerConfig { private static final String SLOW_NAME = \u0026quot;SLOW\u0026quot;; @Bean public Customizer\u0026lt;ReactiveResilience4JCircuitBreakerFactory\u0026gt; slowCusomtizer() { return factory -\u0026gt; { factory.configure(builder -\u0026gt; builder .timeLimiterConfig(TimeLimiterConfig.custom().timeoutDuration(Duration.ofSeconds(2)).build()) .circuitBreakerConfig(CircuitBreakerConfig.ofDefaults()), SLOW_NAME); }; } } 可以看到我们这个自定义的断路器只是改了一下超时时间为2s(默认1s)，并且给定id叫SLOW，其他的保持默认\n配置一下断路器的快速返回的内容是什么\n@RestController @RequestMapping(\u0026quot;/fallback\u0026quot;) public class FallbackController { @RequestMapping(\u0026quot;/order\u0026quot;) public String fallback() { return \u0026quot;this request is break\u0026quot;; } } 这是一个标准的Spring接口\n重新回到yml配置\nspring: cloud: gateway: routes: - id: order-service uri: 'http://192.168.1.233:9300' predicates: - Path=/order-service/** filters: - StripPrefix=1 # 新增配置 - name: CircuitBreaker args: name: SLOW fallbackUri: 'forward:/fallback/order' 第一个name表示的使用的filter是什么，这里当然是CircuitBreaker断路器 args.name表示使用的断路器的id是什么，我这里使用了上面配置的id。实测如果这个id的断路器配置不存在的话，会使用默认配置 args.fallbackUri则是当发生熔断时跳转的url请求地址，就是上面定义的地址 这样就配置好了断路器，接下来测试一下是否成功。\n先把order-service这个服务关掉 访问网关的http://192.168.203.233:9500/order-service/order/create 等待2s直接返回this request is break(或者你定义的响应)则表示成功 请求限流 限流使用到了redis，这里加入spring-boot-starter-data-redis-reactive\npom.xml新增：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis-reactive\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 看官网介绍是需要一个key生成的方法，用于标识一个请求，后续的里程碑版本会提供一些可直接使用的key生成类，但是现在没有，我们尝试自己来写一个\njava配置代码如下：\n@Configuration public class MyLimitConfig { @Bean KeyResolver limitKeyResolver() { return exchange -\u0026gt; Mono.just( Optional.ofNullable(exchange.getRequest().getRemoteAddress()). orElse(InetSocketAddress.createUnresolved(\u0026quot;127.0.0.1\u0026quot;, 80)). getHostName() ); } } 这里单纯的用一个ip地址来表示一个请求\n然后是yml的配置：\nspring: redis: host: 192.168.1.104 port: 6379 password: pw123456 database: 0 timeout: 10S cloud: gateway: routes: - id: order-service uri: 'http://192.168.1.233:9300' predicates: - Path=/order-service/** filters: - StripPrefix=1 - name: CircuitBreaker args: name: SLOW fallbackUri: 'forward:/fallback/order' # 新增 - name: RequestRateLimiter args: redis-rate-limiter.replenishRate: 1 redis-rate-limiter.burstCapacity: 2 redis-rate-limiter.requestedTokens: 1 key-resolver: '#{@limitKeyResolver}' 可以看到增加了一个RequestRateLimiter拦截器，另外Spring这里的限流算法用的是令牌桶算法，不了解可以网络自己搜索了解一下\n四个参数：\nredis-rate-limiter.replenishRate：表示的是每秒生成的令牌数量 redis-rate-limiter.burstCapacity：表示的是令牌桶的大小 redis-rate-limiter.requestedTokens：表示一个请求消耗几个令牌 key-resolver：生成key的方法，使用的是SpringEL表达式 这样配置完成后，当超过请求限制，比如同一秒不同的ip请求3次的话，第三次会返回429的状态。\n结束 Spring的网关在对比zuul的话，zuul1使用的是同步io，zuul2则和springcloud gateway一样使用的是netty。另外spring的网关有很多开箱即用的router,filter。我觉得以后Spring的网关应该会成为主流。\n","date":"2020-04-05","permalink":"https://kazma233.github.io/posts/2020-04/springcloud-gateway%E5%85%A5%E9%97%A8/","tags":["教程","SpringCloud-Gateway"],"title":"SpringCloud-Gateway入门"},{"content":"jaeger是开源的，端对端的分布式链路追踪系统。支持多种编程语言和多种存储方式\n开始 首先需要启动一个jaeger服务，官网有着docker启动开发版jaeger的方式：\n$ docker run -d --name jaeger \\ -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \\ -p 5775:5775/udp \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 14268:14268 \\ -p 14250:14250 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.17 这样一个开发版的jaeger服务就部署好了\n上面这么多端口，官网也有介绍，我这里做一下搬运：\nPort Protocol Component Function 5775 UDP agent accept zipkin.thrift over compact thrift protocol (deprecated, used by legacy clients only) 6831 UDP agent accept jaeger.thrift over compact thrift protocol 6832 UDP agent accept jaeger.thrift over binary thrift protocol 5778 HTTP agent serve configs 16686 HTTP query serve frontend 14268 HTTP collector accept jaeger.thrift directly from clients 14250 HTTP collector accept model.proto 9411 HTTP collector Zipkin compatible endpoint (optional) 其中16686端口是WebUI端口，可以在网页上查看链路的情况，如下图 另外本次要用到的tcp端口是: 6831 引入maven依赖(2.2.6.RELEASE和Hoxton.SR3)：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.opentracing.contrib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opentracing-spring-jaeger-cloud-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.1\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;io.opentracing.contrib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opentracing-spring-rabbitmq-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.opentracing.contrib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opentracing-spring-rabbitmq-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这里说明一下opentracing-spring-jaeger-cloud-starter:3.1.1版本默认的rabbitmq链路追踪会有一个空指针的bug，需要手动引入更高版本的opentracing-spring-rabbitmq-starter才行，所以上面的maven文件才这样做\n配置文件（consul配置中心）：\nopentracing: jaeger: udp-sender: host: 192.168.1.104 port: 6831 所有的配置都在JaegerConfigurationProperties配置文件上 RemoteReporter: 链路报告的配置 flushInterval：刷新间隔 maxQueueSize：最大（消息?）队列大小 HttpSender/UdpSender：以不同的形式配置jaeger的地址 ConstSampler：是否每条链路都采样 ProbabilisticSampler：采集百分比，比如10条采集一条则为0.1 RateLimitingSampler：采样器限速 RemoteControlledSampler：未知 一些默认的配置 如果没有没有给定spring.application.name或者opentracing.jaeger.service-name的值则默认展示的应用名称为: unknown-spring-boot CompositeReporter提供了一些默认的配置：LoggingReporter把追踪日志打印在控制台；RemoteReporter的默认配置是UdpSender，指向localhost:6831 ConstSampler的值为true。 这意味着每条链路都将被采样 使用NoopMetricsFactory，实际上这意味着不会collec指标 在所有的项目都加上opentracing-spring-jaeger-cloud-starter链路追踪后，可以访问一写接口，然后去到jaeger网页上查看：\n每条链路都可以点进去看详情：\n另外说明一点的是jaeger追踪是按照模块区分好了的:\n也就意味着如果你的项目没有用到这个组件的化是可以移除的。这样可以让jar包苗条一点\n总结 之前用的是zipkin，从部署程度来说jaeger要友好一点。代码配置上都差不多。\n两者最近都属于活跃开发中，值得注意的是jaeger比openzipkin晚诞生4年，但start及watch的数量已有后者的一半了，可谓发展迅猛。另外还有一点值得注意的是jaeger是Cloud Native Computing Foundation的项目，因此云原生的项目都会支持它。 来源\n","date":"2020-04-04","permalink":"https://kazma233.github.io/posts/2020-04/jaeger%E5%85%A5%E9%97%A8-java%E7%89%88%E6%9C%AC/","tags":["教程","jaeger"],"title":"jaeger入门-java版本"},{"content":"consul的入门\n前言 Consul用的是Golang语言编写，所以很自然的实现了多平台运行的能力\nConsul支持的功能有这些：\n服务发现：服务提供者可以注册服务在上面，其他应用程序可以通过Consul来访问[DNS, HTTP]这些服务 健康检查：Consul可以提供任意数量的健康检查。运维可以清楚的看到这些服务的状况 K/V存储：键值存储用于任何地方，包括配置中心，简单易用，使用HTTP API即可 Secure Service Communication Multi Datacenter 服务发现 pom.xml加入依赖(2.2.6.RELEASE和Hoxton.SR3)：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-consul-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 在bootstrap.yml文件里：\nspring: application: name: product-service cloud: consul: host: 127.0.0.1 port: 8500 在启动类上添加注解@EnableDiscoveryClient注解(不管是Eureka还是Nacos都是基于Spring的接口实现了服务注册的功能):\n@SpringBootApplication @EnableDiscoveryClient public class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); } } 很容易看懂这些配置，配好Consul的主机地址和端口就可以了，这时候启动就能看到注册到了Consul上面，如下图所示： 如果不需要注册中心，只是需要服务注册的话，可以把上面bootstrap.yml的内容写在application.yml里。这里涉及到的是配置文件加载顺序的问题。因为在加载配置之前，需要从注册中心先拉取下配置文件来，再去初始化其他服务，而bootstrap.yml里的配置是系统级的，会比其他自动配置早加载。\n配置中心 配置中心有一些配置的描述很晦涩，这里拿出来特意说一下。\npom.xml加入依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-consul-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 在bootstrap.yml文件里：\nspring: application: name: product-service profiles: active: dev cloud: consul: host: 127.0.0.1 port: 8500 # discovery下的都是多余的，因为默认都是true discovery: enabled: true register: true deregister: true config: enabled: true format: YAML prefix: config default-context: product-service profile-separator: '::' data-key: data 主要看config下的配置解释：\nformat: 表示这个配置的值是一yml文件 enabled: setting this value to \u0026ldquo;false\u0026rdquo; disables Consul Config prefix: sets the base folder for configuration values default-context: sets the folder name used by all applications profile-separator: sets the value of the separator used to separate the profile name in property sources with profiles 看完一脸懵逼，除了本身的英文水品不高外，没有示例的话完全看不懂啊喂\n接下来请看示例： 上图是我的一个配置，路径是config/product-service::dev/data，发现了什么吗？对的，配置的路径就是按照prefix + default-context + file-separator + spring.profiles.active + data-key组合而成的。\n配置好后，启动项目，Spring就会先从Consul来拉取配置，然后再去配置其他的自动配置项\n接下来看看自动刷新配置的功能，作为合格的配置中心，热修改配置是必须的能力，同样的是结合了Spring来实现的，只需要加入Spring的注解就好了，如下demo：\nconsul新加一个配置\nconfig: data: test 然后在代码里加入@RefreshScope注解\n实体类Config.java\n@Data @Component @RefreshScope @ConfigurationProperties(\u0026quot;config\u0026quot;) public class Config { private String data; } 启动类ProductApplication.java\n@RestController @SpringBootApplication @EnableDiscoveryClient @EnableConfigurationProperties public class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); } @Autowired private Config config; @GetMapping(\u0026quot;/example\u0026quot;) public String getExample() { return config.toString(); } } 当访问http://127.0.0.1:9200/example时，可以访问到example配置的值，第一次访问是Config(data=test)\n接下来保持这个状态，直接在Consul里修改配置\nconfig: data: real 再次访问http://127.0.0.1:9200/example，发现返回的值是Config(data=real)\n至此，配置中心的热加载也成功了\n总结 之前学了SpringCloud Config和SpringCloud Bus，感觉Consul的操作要少很多，在实践起来也会好一点，不过不知道流行程度如何。总体来说是一个很不错的服务注册和配置中心（废话）。\n","date":"2020-04-02","permalink":"https://kazma233.github.io/posts/2020-04/consul%E7%9A%84%E5%85%A5%E9%97%A8/","tags":["教程","consul"],"title":"consul的入门"},{"content":"基础基础的基础\n获取和创建项目 init 初始化一个git项目\n# 初始化当前目录为git仓库 git init # 初始化指定目录为git仓库 git init [repo_dir] clone 将存储库克隆到新目录\n# 拉去远程git仓库到本地，并且可以指定拉取的目录 git clone git_address [dir] 基本操作 add 将文件添加到git\ngit add . # example: git add *.java git add [pattern] status 显示当前git的仓库的状态\ngit status \u0026rsquo; \u0026rsquo; = unmodified\nM = modified\nA = added\nD = deleted\nR = renamed\nC = copied\nU = updated but unmerged\ndiff 显示git的更改\ngit diff git diff develop git diff develop master git diff filename commit 提交代码，暂存到存储库\ngit commit -m \u0026quot;commit message\u0026quot; restore 恢复文件\ngit restore filename reset 重设HEAD指针\nUndo add 在你add file之后，却需要拉取最新的代码，可以尝试git reset $ edit (1) $ git add frotz.c filfre.c $ mailx (2) $ git reset (3) $ git pull git://info.example.com/ nitfol (4) Undo a commit and redo $ git commit ... $ git reset --soft HEAD^ (1) $ edit (2) $ git commit -a -c ORIG_HEAD (3) 当您记得刚提交的内容不完整，或者拼写错误的提交消息，或者两者兼而有之时，通常会执行此操作\n对工作树文件进行更正\nreset将旧的头复制到.git/ORIG_HEAD; 通过从其日志消息开始重做提交。 如果不需要进一步编辑消息，则可以给-C选项。\nHEAD^2 表示指针往前移动两步\nUndo a merge or pull\ngit pull git reset --hard rm 从工作树和索引中删除文件\ngit rm不会仅从您的工作目录中删除文件\ngit rm pattern 分支与合并 branch 查看，删除，创建分支\n# 创建分支 git branch feature/id111 # 删除远程分支 git branch -d -r origin/devlop # 删除未合并的分支 git branch -D test # 查看所有分支 git branch -a checkout 切换分支，或者还原文件\n# 创建分支，并切换 git checkout -b feature/id111 ## 还原hello.c文件 git checkout -- hello.c # 切换分支 git checkout mytopic # 当 当前分支有文件和要切换到的分支更改不同时，将不允许切换分支。可以使用-m参数，但是有可能会冲突 git checkout -m mytopic switch 切换分支\ngit switch master # 同checkout-m参数 git switch -m mytopic merge 分支合并\n# 将分支feature/id111合并到当前分支 git merge feature/id111 log 展示提交日志\ngit log git log --oneline --graph 配置文件.git/config\n[i18n] commitEncoding = UTF-8 logOutputEncoding = UTF-8 tag 打标签\ngit tag tag_name # 补标签 git tag -a tag_name commit_id 共享和提交项目 fetch 从另一个存储库下载对象和引用\npull 将更改从远程存储库合并到当前分支。 在默认模式下，git pull是git fetch的简写，其次是git merge FETCH_HEAD。\n$ git pull $ git pull origin push 推送代码。使用本地引用更新远程引用，同时发送完成给定引用所需的对象。\ngit push git push origin # 删除远程分支 git push origin --delete serverfix remote 管理一组跟踪的存储库\n创建一个新的git库。并合并到远程仓库 $ mkdir project.git $ cd project.git $ git init $ git remote add -f -t master -m master origin git://example.com/git.git/ $ git merge origin $ git push -u origin master 其中-t是分支。一般直接git remote add origin 地址即可\nrebase 详见rebase使用\n参考：\n中文 原文 ","date":"2020-03-13","permalink":"https://kazma233.github.io/posts/2020-03/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","tags":["教程","git"],"title":"git常用操作"},{"content":"git分支管理规范（摘抄）\n分支管理规范 master分支\n主分支，永远处于稳定状态，对应当前线上版本 以 tag 标记一个版本，因此在 master 分支上看到的每一个 tag 都应该对应一个线上版本 不允许在该分支直接提交代码，只允许release分支合并或者hotfix分支合并 develop 分支\n开发分支，包含了项目最新的功能和代码，所有开发都依赖 develop 分支进行 小的改动可以直接在 develop 分支进行，改动较多时切出新的 feature 分支进行 注： 更好的做法是 develop 分支作为开发的主分支，也不允许直接提交代码。小改动也应该以 feature 分支提 merge request 合并，目的是保证每个改动都经过了强制代码 review，降低代码风险\nfeature 分支\n功能分支，开发新功能的分支 开发新的功能或者改动较大的调整，从 develop 分支切换出 feature 分支，分支名称为 feature/idxxx 开发完成后合并回 develop 分支并且删除该 feature/idxxx 分支 release 分支\n这是发布分支，新功能合并到 develop 分支后，基于 develop 分支准备发布新版本时使用的分支 当 develop 分支完成功能合并和部分 bug fix，准备发布新版本时，切出一个 release 分支，来做发布前的准备，分支名约定为release/xxx 发布之前发现的 bug 就直接在这个分支上修复，确定准备发版本就合并到 master 分支，完成发布，同时合并到 develop 分支 hotfix 分支\n紧急修复线上 bug 分支 当线上版本出现 bug 时，从 master 分支切出一个 hotfix/xxx 分支，完成 bug 修复，然后将 hotfix/xxx 合并到 master 和 develop 分支(如果此时存在 release 分支，则应该合并到 release 分支)，合并完成后删除该 hotfix/xxx 分支 概述 以上就是在项目中应该出现的分支以及每个分支功能的说明。 其中稳定长期存在的分支只有 master 和 develop 分支，别的分支在完成对应的使命之后都会合并到这两个分支然后被删除。简单总结如下：\nmaster 分支: 线上稳定版本分支\ndevelop 分支: 开发分支，衍生出 feature 分支和 release 分支\nrelease 分支: 发布分支，准备待发布版本的分支，存在多个，版本发布之后删除\nfeature 分支: 功能分支，完成特定功能开发的分支，存在多个，功能合并之后删除\nhotfix 分支: 紧急热修复分支，存在多个，紧急版本发布之后删除\n提交规范 听说用的比较多的是Angular的标准\n\u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; \u0026lt;BLANK LINE\u0026gt; \u0026lt;body\u0026gt; \u0026lt;BLANK LINE\u0026gt; \u0026lt;footer\u0026gt; type: 本次 commit 的类型，诸如 bugfix docs style 等，在下方有说明 scope: 本次 commit 波及的范围 subject: 简明扼要的阐述下本次 commit 的主旨 使用现在时的命令性语气 ，present tense: \u0026ldquo;change\u0026rdquo; not \u0026ldquo;changed\u0026rdquo; nor \u0026ldquo;changes\u0026rdquo;. 首字母不要大写 结尾无需添加标点 body: 应包括改变的动机，并将其与以前的行为进行对比。如需换行，则使用 |。 footer: 描述下与之关联的 issue 或 break change。可以附上issue链接。公司内部应该很少会用到 Type的类别说明：\nfeat: 添加新特性\nfix: 修复bug\ndocs: 仅仅修改了文档\nstyle: 仅仅修改了空格、格式缩进、都好等等，不改变代码逻辑\nrefactor: 代码重构，没有加新功能或者修复bug\nperf: 增加代码进行性能测试\ntest: 增加测试用例\nchore: 改变构建流程、或者增加依赖库、工具等\n示例 也是最小需要的提交信息，至少需要type和commit\nfeat: 用户登录\nfix: 用户权限bug\n来源(略作修改) 您必须知道的 Git 分支开发规范 项目中的 Git 使用规范 ","date":"2020-03-04","permalink":"https://kazma233.github.io/posts/2020-03/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86%E8%A7%84%E8%8C%83/","tags":["教程","git"],"title":"git分支管理规范"},{"content":"本文追求在不对手机root，尽量少操作情况下，打造一台在国内环境对流氓APP有着不错控制的安卓手机\n前前言 本来只想介绍几个软件的，写着写着就思维飞跃了。每次写东西没有大纲，一写就容易思维扩散，脱离主题，尴尬。\n前言 有人把安卓和Android做了区分，安卓代指没有预装Google服务的Android操作系统，而Android才是完整的Android操作系统。为了方便表达，这里我也会做区分对待，把没有Google服务的称为安卓，而有Google服务的称为Android\n消息通知 我们之所以能够接收到消息通知，是因为我们的手机在后台运行着接收消息的服务，他们是7*24小时不间断运行着的(即使是对后台运行非常吝啬的iPhone也是)\n一起先看看正常情况下消息推送的方式(不考虑本地消息通知,不包含安卓):\n应用程序(APP)后台-\u0026gt;苹果(APNs)/谷歌(FCM)的推送后台-\u0026gt;用户接收\nAPP后台: 通知的发起者，一般是服务器端，告诉苹果要推送通知给用户 推送后台: 通知的转发者，接收到发起者的推送通知请求后，根据信息内容来把消息推送给用户 用户接收: 这时候用户就能看到消息了 安卓的消息通知：\n由于一些原因，我们的互联网无法访问谷歌，而安卓手机上的消息通知用的是谷歌的FCM，所以国内是没法统一的使用FCM来做消息推送的。没有统一的消息推送服务，就导致国内发送消息通知的方式百花齐放\n国内做通知服务的有三种，一种是安卓的OEM厂商，比如MiPush(小米推送)和hms(华为推送)，它们集成到自己定制化的安卓系统上，代替FCM；一种是推送服务商，比如极光推送，他们专注于做推送服务，帮助中小型公司快速的搭建推送服务；第三种的话就是APP大厂，比如腾讯，阿里，百度等，他们有自己的实力来做推送服务\n除了OEM运营商把自己的推送集成到了系统，就像FCM一样，其他的都需要在后台运行一个服务来接收推送，非常的可怕\n一些进展 当然了，这种事情想统一靠厂商是没有办法了，所以工信部出手了，工信部旗下的中国泰尔实验室牵头成立了移动应用信息推送技术联盟(统一推送联盟)联合Android绿色公约，所有的APP需要遵守，推送都要用统一推送联盟才行。相当于成立了国内版本的APNs/FCM，一统通知江湖，指日可待 (吧)\n好了，把流氓软件的原因给扯了一些，现在该回到正题了(什么？原来还没开始)\n整治 你以为工信部牵头就没有流氓APP了？你错了，该流氓的还是流氓，毕竟利益在这\n来看看这些整治流氓的正义的伙伴：\nShizuku:\n让你的应用直接使用系统API\n这其实不是给用户来使用的，你可以把它当作是基础服务，给后面那些管理软件(App Ops和冰箱)提供服务\n你唯一要做的就是手机用USB连上电脑，在命令行输入一句adb的命令激活它就好了，估计这个是唯一的门槛了(2020-07-26: 新版本启动方式变更)。\nadb shell sh /data/user_de/0/moe.shizuku.privileged.api/start.sh 如无问题你将会在Shizuku中看到已启动成功\n另外重启手机后需要重新用电脑连接然后运行这个命令\nadb的安装: Windows可以使用scoop: scoop install adb，mac上可以使用homebrew App Ops:\n简而言之，App Ops 是一个修改 Android 系统中的 \u0026ldquo;appops\u0026rdquo; 设置 的应用\n可以简单的理解为权限管理，但是和普通的弹窗授权不同 在APP允许的权限，如果在App Ops里拒绝了，那APP也拿不到这个权限，很好绕过了不给权限就不给用的问题，而且管理权限的粒度要细很多 另外在App Ops里修改过的权限，就算是重启了手机，卸载了App Ops，这些权限设置还是存在的，因为这些权限其实是安卓系统隐藏未暴露出来的，修改的是系统的设置 冰箱:\n没有找到官方的说法，不过功能也很单一，就像是禁用系统APP一样的禁用普通的APP\n配合Shizuku使用，其他模式不推荐 绿色守护:\n智能休眠应用\n刚好最近少数派有人写了一篇关于绿色守护的文章，可以看看，不过他这边演示的是root后的，如果不root会少一些功能，但核心功能不受影响 有特殊的adb命令，也可以开启一些高级功能 黑域:\n个人并不是特别喜欢，光是看到微信登录就很怕了\n炼妖壶:\nAPP分身\n个人没有这个需求，没有仔细体验，而且项目处于测试阶段，仅作尝鲜使用\n推荐 如果你是非常懒的用户，那么推荐你至少装一个绿色守护，装上就能用 如果你勤奋一点，想要去捣鼓一下的话(也就是多了adb命令)，尝试Shizuku配合App Ops和冰箱，会让你对安卓流氓软件有一个充足的控制，而且绿色守护功能也会得到增强 其他的我没有用过，黑域需要新的adb命令，应该也很简单，炼妖壶的有需要也可以看看 很喜欢Shizuku 引用和扩展 Shizuku命令 不用 root 也能优化好手机？为此我试了一下这十款应用-少数派 ","date":"2019-11-17","permalink":"https://kazma233.github.io/posts/2019-11/android%E6%B5%81%E6%B0%93app%E6%95%B4%E6%B2%BB%E5%8A%9E%E6%B3%95%E6%8E%A8%E8%8D%90/","tags":["教程","Android"],"title":"Android流氓App整治办法推荐"},{"content":"使用Docker部署V2Ray\n前言 之前写过一篇文章，在Ubuntu上来部署Shadowsocks来科学上网，随着科学上网的阻碍加大(防火墙加高)，Shadowsocks的特征被识别等情况，速去了解到了新的代理工具，也就是现在要说的V2Ray\n开始吧 先说好前提，这里使用的环境是在Docker上，利用docker compose来启动创建和启动容器，所以应该是所有能跑Docker的机器上都能这么做。另外如果这两个东西不了解需要去提前了解。或者你想要找其他的安装方式，可以参考官网的安装文档\n其实使用Docker的话对新手算是引入了更大的复杂度，但是为了不影响主机的情况，使用Docker来部署和测试v2ray还是很有必要的\nV2Ray提供了两个V2Ray的镜像可以选择:\nv2ray/official: 包含最新发布的版本，每周跟随新版本更新 v2ray/dev: 包含由最新的代码编译而成的程序文件，随代码库更新 为了减小问题的可能性，使用official的镜像，地址在这\n登录上代理服务器，安装好docker和docker-compose，并且创建好docker-compose.yml，名字需要一样，或者你使用docker-compose的时候用-f命令来指定文件名也可以。文件内容如下:\nversion: '3.1' services: v2ray: image: v2ray/official restart: always ports: - 23333:23333 volumes: - ~/v2ray/config:/etc/v2ray - ~/v2ray/logs:/var/log/v2ray command: v2ray --config=/etc/v2ray/config.json ports设置说明了服务器监听的端口是23333，映射在本地也是23333，左边是本地端口，右边是容器端口 然后设置了两个volumes，用来把本地的磁盘数据共享到容器里，这样可以直接修本地配置然后重新启动就可以生效，也可以看历史日志。比如配置文件是放在了本地的~/v2ray/config下，这样在容器里的目录是/etc/v2ray，所以启动容器指定配置文件地址的时候用的是/etc/v2ray/config.json，后面我们的配置文件直接放在~/v2ray/config/config.json下就好了 创建好配置v2ray的文件，名字是config.json，放在~/v2ray/config下。另外这里推荐两个v2ray配置生成的网站这个和这个\n{ \u0026quot;log\u0026quot;: { \u0026quot;access\u0026quot;: \u0026quot;/var/log/v2ray/access.log\u0026quot;, \u0026quot;error\u0026quot;: \u0026quot;/var/log/v2ray/error.log\u0026quot;, \u0026quot;loglevel\u0026quot;: \u0026quot;info\u0026quot; }, \u0026quot;dns\u0026quot;: {}, \u0026quot;stats\u0026quot;: {}, \u0026quot;inbounds\u0026quot;: [ { \u0026quot;port\u0026quot;: 23333, \u0026quot;listen\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;protocol\u0026quot;: \u0026quot;vmess\u0026quot;, \u0026quot;settings\u0026quot;: { \u0026quot;clients\u0026quot;: [ { \u0026quot;id\u0026quot;: \u0026quot;id一般是自动生成\u0026quot;, \u0026quot;alterId\u0026quot;: 64 } ] }, \u0026quot;streamSettings\u0026quot;: { \u0026quot;network\u0026quot;: \u0026quot;tcp\u0026quot;, \u0026quot;security\u0026quot;: \u0026quot;none\u0026quot;, \u0026quot;tcpSettings\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;none\u0026quot; } }, \u0026quot;tag\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;sniffing\u0026quot;: { \u0026quot;enabled\u0026quot;: true, \u0026quot;destOverride\u0026quot;: [ \u0026quot;http\u0026quot;, \u0026quot;tls\u0026quot; ] } } ], \u0026quot;outbounds\u0026quot;: [ { \u0026quot;tag\u0026quot;: \u0026quot;direct\u0026quot;, \u0026quot;protocol\u0026quot;: \u0026quot;freedom\u0026quot;, \u0026quot;settings\u0026quot;: {} }, { \u0026quot;tag\u0026quot;: \u0026quot;blocked\u0026quot;, \u0026quot;protocol\u0026quot;: \u0026quot;blackhole\u0026quot;, \u0026quot;settings\u0026quot;: {} } ], \u0026quot;routing\u0026quot;: { \u0026quot;domainStrategy\u0026quot;: \u0026quot;AsIs\u0026quot;, \u0026quot;rules\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;field\u0026quot;, \u0026quot;ip\u0026quot;: [ \u0026quot;geoip:private\u0026quot; ], \u0026quot;outboundTag\u0026quot;: \u0026quot;blocked\u0026quot; } ] }, \u0026quot;policy\u0026quot;: {}, \u0026quot;reverse\u0026quot;: {}, \u0026quot;transport\u0026quot;: {} } 启动 使用命令docker-compose up -d来启动，然后使用docker logs container-id来查看日志，最后检查端口lsof -i:23333是否处于监听状态。后面有问题的话可以先看看v2ray的日志，后续再尝试检查v2ray的配置，docker-compose的配置\n连接 这里使用的本地客户端是clash for windows，配置如下:\nport: 7890 socks-port: 7891 allow-lan: true mode: Rule log-level: silent external-controller: 0.0.0.0:9090 Proxy: - name: mine type: vmess server: 服务器IP port: 23333 uuid: 之前服务器上的uuid alterId: 64 cipher: auto Proxy Group: - name: auto type: url-test proxies: - mine url: http://www.gstatic.com/generate_204 interval: 300 - name: Proxy type: select proxies: - mine - auto Rule: - MATCH,auto 具体的配置内容参考git文档，有一个This is an example configuration file，展开就能看到示例。或者你也可以在这里找到你自己喜欢的工具\n最终的情况是你可以打开谷歌找到你想要的内容(废话)\n总结 这次写着写着发现东西越来越多，到后面很多都是单纯的丢一下文档和配置了。发现现在的科学上网难度真是越来越大了，不由得感叹一下。\n主要的内容：\nv2ray配置和使用 clash配置和使用 docker的安装使用和docker-compose配置 ","date":"2019-10-29","permalink":"https://kazma233.github.io/posts/2019-10/%E4%BD%BF%E7%94%A8docker%E9%83%A8%E7%BD%B2v2ray/","tags":["教程","V2Ray"],"title":"使用Docker部署V2Ray"},{"content":"前文 网上有很多教程，教你怎么在有Windows和UEFI环境的基础上，安装Ubuntu组成双系统，我这就不去细写这些东西了，主要说一些坑和纠正一些过时的东西，所以如果你想靠我这篇文章学会从0安装Ubuntu是不行的\n现在用传统BIOS的方式安装系统基本上都已经消失了，就不做讨论(具体区分可以自行搜索，也有很多文章)。所以我安装Ubuntu也是用的UEFI的启动方式安装，这个时候是要有EFI分区的，用于引导启动系统\n安装 这里大概列一下步骤，和装Windows差不多，想要特别说明的也直接加进去了\n先需要一块U盘，好像不用很大的硬盘，我这边32G的U盘整下来也就用了1.86GB，如果是Windows安装，估计要8G往上，因为Windows这ISO镜像就4个多G了\n如图去处理这块U盘，用的软件是rufus，请不要骚操作，就像我之前把文件系统改成了NTFS就一直装不了，按默认的，推荐的操作去做就好了，该下载下载，该点推荐就点推荐。\n然后需要在PC的磁盘上空出一块未格式化的存储来安装Ubuntu，具体空在哪块磁盘也全看个人，不过我暂时还没试过放在和Windows不同磁盘的情况。至于大小的话，看你是装来玩的还是干嘛，玩的话随便分个10，20G就可以了，如果是主力系统，那往多的方向去分吧，你这里给出的空间大部分都会用来安装软件和自己的文件用，系统什么的占用的并不多\n然后就可以重启Windows，从U盘启动，不出意外会出现GRUB的界面，直接选install ubuntu就好了\n这里主要说下操作磁盘这块，一般我都是选其他(else)，因为我安装在和Windows同一块磁盘上，这时候会进到磁盘管理的界面 把EFI分区给好，我直接给了1G，目测不用这么大 挂载根目录(/)，这里系统大部分东西都在这，包括你安装的软件也在 挂载个人工作目录(/home)，这里不要也行，但是我觉得还是个人文件和系统分开会好一点，剩下的容量都怼这就好了 有一些争议的分区(我只分了上面三个分区): swap: 我这里是16G的内存，这内存交换分区我是用不到了，不要 /boot: 不需要，UEFI分区要的是EFI分区来启动系统 装完会叫你重启，之后还是会进入到GRUB，但是选项不同了，选项有Ubuntu和Windows和其他两个设置选项，10s不选默认就进第一个了，我这第一个是Ubuntu，进去就可以用了。在黑屏的时候可以拔掉U盘，省的如果设置了第一启动项是U盘，又进了U盘的GRUB了\n总结 我这边大概也就是这几个坑\n配置启动盘瞎操作，把U盘的文件系统改成了NTFS，结果就不能进到GRUB，或者进去了是通过传统BIOS的方式，导致装系统压根就没有创建EFI分区的选项，这样装1w遍也进不去系统 看网上分区看蒙圈了，实际上UEFI的话，只要EFI分区和/分区就好了，其他的去了解分区功能再去安装 搜索出来的文章记得加UEFI的方式，不要看太老的 参考(单纯是维基百科的链接) UFEI GPT BIOS MBR ","date":"2019-09-27","permalink":"https://kazma233.github.io/posts/2019-09/windows%E4%B8%8B%E5%AE%89%E8%A3%85ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F/","tags":["教程","系统","Ubuntu"],"title":"windows下安装Ubuntu组成双系统的跳坑指南"},{"content":"是时候使用自动部署了\n身为一个后端程序员，对于部署自己开发服务肯定是很开心的，因为经过迭代开发，服务终于可以交给用户(或者自己)使用了，然而你发现了吗？在部署的时候却总在做着重复的，容易出错的事情，比如配置文件的更换，上传jar包(SpringBoot)到服务器，感觉这些事情做了一遍又一遍的，这些名命令行敲了一次又一次，是不是开始感觉有一点无聊了呢？如果是的话，那么是时候来试试自动部署了。\n先交代一下环境 之前的一段时间我用python脚本简化了发布的流程，但是给我的感觉很不好，虽然也可以达到一键发布的效果，但感觉还是不舒服，所以才想上Jenkins。下面说一下我大概的环境。\nUbuntu 18 LTS，一台用来发布服务(发布服务的环境后面会主动介绍)，一台用来部署服务(上面有一个nginx运行在80和443端口上，会反向代理从发布服务器部署上来的SpringBoot服务，意味着发布的时候我只要运行这个jar就好了) SpringBoot的一个博客项目，比较简单 jdk用的是OpenJDK11，SpringBoot支持jdk11后就切换过来了，主要是Oracle的JDK太难下载了现在 构建工具用的是Gradle，也没啥，就图个新鲜把 没有部署其他的服务，比如mysql等等，因为他们在我的另一台数据机器上 说一下流程 我这边把一个Spring Boot的项目一键自动部署到服务器上。其中简单的涉及到了配置文件的替换，gradle构建，上传jar包，运行jar包。\n先是在ubuntu这台发布服务器上安装好Jenkins，然后同时安装好构建的环境，比如Gradle和Openjdk11 对Jenkins进行这些工具的配置 在Jenkins上创建一个自动部署的项目，部署的全过程都在这里 build now，一键部署，查看日志排除，并查看服务是否运行 安装Jenkins 在发布服务器上安装Jenkins，安装的教程还是挺多的，如果是Ubutnu的话，我这边就简单的贴一下命令行命令吧，也很快。\nwget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add - sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ \u0026gt; /etc/apt/sources.list.d/jenkins.list' sudo apt-get update sudo apt-get install jenkins 然后相关文件的位置:\n配置文件在: /etc/default/jenkins 日志文件(可以查看到Jenkins的初始密码，后面需要用到)在: /var/log/jenkins/jenkins.log 其他的事项:\n如果不更改默认配置的话，那么Jenkins默认运行在8080端口上，访问192.168.0.107:8080(视环境而定)即可 一进去会要你输入默认的密码，在上面说到的日志文件里(独立的长串字符，我安装的很早了，没有图片了)，在Jenkins的日志上可以看到密码，复制输入 然后是选择插件，这里除了默认勾上的外，我还做了这些: 取消勾选ant和svn 勾选了Gradle Plugin，Publish Over SSH，SSH Plugin 然后等待插件的安装，最后设置一个用户进入即可看到如下页面(我这个页面是构建过一个项目的，会有点差异，不过进来了就说明配置好了) 使用docker来安装Jenkins\n上述内容在使用docker部署之后，有少数不同:\n端口使用容器映射，我使用了7000端口 默认的密码需要去容器内查看 所有的环境都让jenkins去安装(后面的本地环境都换成jenkins默认的) 准备好构建环境 到这里你应该已经安装好了Jenkins，接下来就是把发布服务器上的构建环境给搭建好了，我这里准备好了OpenJDK11和Gradle，JDK11的话用的Ubuntu的apt命令安装，Gradle是先去安装了SDKMAN，然后用SDKMAN安装的sdk命令安装好了gradle。\n还有就是我的项目是放在github上的，随意需要下载git，同样使用的apt直接装一个就好了\n配置Jenkins 配置工具 先Manage Jenkins-\u0026gt;Global Tool Configuration\n配置Gradle\n可以选择让Jenkins自动下载，勾上Install automatically就好了 我选择用我自己的，也就配一个目录就好了 配置git\n这里我就默认了 然后Ok即可(我习惯先apply然后ok)\n配置系统设置 配置Publish over SSH，用来把打包好的文件上传到服务器，并且执行命令 之前没仔细看，发现好像只能用ssh key来上传 Passphrase: ssh key的密码(如果有的话) Path to key：ssh key的路径 Key：key的内容，和Path to key填一个就好了 SSH Servers Name: 取一个好记的名字 Hostname: 主机名 Username: 用户名 Remote Directory: 全局的远程目录，在后面上传文件的时候会加上这个前缀 再往下就是一些代理设置，我设置了一下，默认情况下是不用设置的(我的小鸡在日本，慢的一批) 同样ok即可，然后回到首页\n配置项目的配置文件 因为我的项目在git上是公开库，所以一些正式环境的东西没有提交在上面，所以这边会把正式环境的配置放在Jenkins上，拉去git项目下来，把配置文件给替换就好了\n依旧是Manage Jenkins-\u0026gt;Managed files-\u0026gt;Add a new Config-\u0026gt;Custom file\n在Content里把配置文件的内容写好就好了\n创建并配置项目 该配置的都配置好了，现在就可以开始创建一个自动部署的项目了 点击New Item然后输入项目名并先选择Freestyle project，然后OK即可 进去后会进入到项目的配置界面，很多选项可以通过英文大概的看懂，所以我只说我这边会用到的。\n首先是把源码给拉取下来，在Source Code Management选项卡勾选git，然后在Repository URL里输入项目的git地址就好了，我的是公开库所以不用认证就可以拉下来，如果是私有库，需要认证，点击Add那块跟着操作走就好了 把之前设置的配置文件拷贝进项目里 设置build里的Gradle\nAdd build step-\u0026gt;Invoke Gradle script 这里如果自己有配置Gradle就选自己的，也可以用Use Gradle Wrapper 设置build的push ssh server\nAdd build step-\u0026gt;Send files or execute commands over SSH 这里配置好让Jenkins自动上传打包好的文件，然后执行命令行去运行，name就是之前配置的Publish over SSH里填的名字，这里会先上传文件，然后运行Exec command 这里有一个Remove prefix当时我理解了好一会，实际上就是在上传的时候Remote directory+Source files才是上传的目录，但我们服务器的目录肯定和本地不一样的。我们只是想要Remote directory+xxx.jar这样的形式。所以这个Remove prefix就是起这个作用，向我上面配置的可以把我上面本地目录的路径上的build/libs给清空掉，这样我的上传目录就是Remote directory+blog-service-4.0.0.jar了。 配置完了，点击ok保存，回到了当前项目的面板，左边有个Build Now，启动部署吧!!!\n查看日志发现问题并解决 看起来一切都是很美好的，但是本来发布一个服务就不是一件轻松的事情，有很大的可能会build失败，我们去哪里看构建的进程日志呢。\n在项目左下角有一个Build History，每一个历史都可以点进去看\n进去后点击Console Output就可以看到部署的日志啦，根据报错不断调整重试，最终完成部署。\n其他 下面是列一些进阶或者是需要考虑的地方\n数据库的更改，需要运行SQL脚本 可能需要同时部署其他的服务或者依赖其他服务的服务(微服务这样的) webhooks docker 其实一路走下来，发现Jenkins就像是流水线，一步步的把任务完成，直到结束，任务的顺序可以任意调整，非常自由。\n感觉Jenkins包含的东西很多，我也可以慢慢的摸索，想办法去实践，其实在公司环境有自动部署需求的话，那应该最容易学会了，因为有真实环境嘛。其实写了这么多，我感觉也没有写完，也很怕漏掉什么，不过慢慢发现吧，也欢迎大家提问纠错，一起讨论学习\n更新 2019-11-23: 使用docker部署jenkins，更加方便，且可备份 ","date":"2019-09-06","permalink":"https://kazma233.github.io/posts/2019-09/jenkins%E5%85%A5%E9%97%A8/","tags":["教程","Jenkins","运维"],"title":"Jenkins入门"},{"content":"用命令行一时爽，一直用命令行一直爽\ngit的merge操作 前情提要：这里假设要把feature/BACKEND-136合并到RELEASE/1.1上\n切换到要合并到的分支上，使用git checkout RELEASE/1.1\n如果不记得分支名字了可以用git branch -a查看下分支信息\n执行一下git pull，保证本地该分支代码为最新的\n使用git merge feature/BACKEND-136命令将feature/BACKEND-136合并到当前所在的分支RELEASE/1.1上\n然后可以用git log命令看一下提交记录，可以看到后面的都是feature/BACKEND-136分支上的注释(里面\u0026lt;E8\u0026gt;什么的是中文乱码，所以以后提交要不都用英文吧，对windows用户友好，😓)\n现在我想要把这些注释都合成一行，不需要那么多注释，只想要这一个注释：finish feature BACKEND-136，那接下来就可以用git的rebase命令了\n按下q退出git log的状态，我这里执行git rebase -i e1ba525035be07564ca4a484a054a8edf5112774，里面一大串指的是commit后面的那串编号(看别人的貌似可以缩写)，他会把这个commit之上的commit都拿到，让你后续进行操作。 然后会看到一个vim界面类似的，按下i开始编辑，我把除了第一个的pick改成了s\npick：保留该commit（缩写:p） reword：保留该commit，但我需要修改该commit的注释（缩写:r） edit：保留该commit, 但我要停下来修改该提交(不仅仅修改注释)（缩写:e） squash：将该commit和前一个commit合并（缩写:s） fixup：将该commit和前一个commit合并，但我不要保留该提交的注释信息（缩写:f） exec：执行shell命令（缩写:x） drop：我要丢弃该commit（缩写:d） 大概意思是把s标注的都往前合并，最后就只留下第一个commit了。然后按下esc，输入:wq回车出来\n这时会来到另一个页面(也是vim样界面)，写上这个commit的注释就好了，把其他的通通删掉\n改成了这样:\n把注释改完之后，同样的方式：esc，输入:wq回车退出\n再次执行git log看看，发现你之前的记录都消失了，只留下了最后你输入的哪个commit\n最后万事大吉直接git push就好了，希望不要出意外，少女祈祷中。就完事了。\n来源 一些来源参考: https://www.jianshu.com/p/4a8f4af4e803\n","date":"2019-05-16","permalink":"https://kazma233.github.io/posts/2019-05/git-merge%E6%93%8D%E4%BD%9C/","tags":["教程","git"],"title":"git merge操作(rebase)"},{"content":"docker在安装某些软件时很方便，记录下来，顺带学习docker\n安装docker 详细看官方文档\n一个软件 安装portainer(管理docker) 详情看这里 docker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 基本命令 run\ndocker run [OPTIONS] IMAGE [COMMAND] [ARG...] -p 表示将容器的某个端口暴露出来， 比如-p 7000:8000表示将容器的8000端口暴露出来并映射到本地的7000端口 -i 表示可操作，即使未连接STDIN也保持打开状态 -t 分配伪TTY，和-i连-it 表示容器的 Shell 映射到当前的 Shell -d 在后台运行容器并打印容器ID -v 绑定挂载卷，用于容器卷和本地卷绑定，比如-v /docekr/mysql/data:/mysql/data表示将容器的目录/mysql/data绑定到本地的/docekr/mysql/data目录上 -e 设置环境变量 \u0026ndash;rm 退出时自动删除容器 \u0026ndash;name 为容器分配一个名称 exec\ndocker exec [OPTIONS] CONTAINER COMMAND [ARG...] 用于进入一个启动的容器: docker exec -it container_name bash commit\ndocker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 用于创建一个自己的镜像: docker commit 89a47b5b749e book-service:latest 其他的比如container,image,logs命令都很常用，都可以用docker 命令 --help来查看说明\ndockerfile Docker可以通过阅读Dockerfile中的指令来自动构建映像。 Dockerfile是一个文本文档，其中包含用户可以在命令行上调用以组装映像的所有命令。使用docker build的用户可以创建自动执行的构建，该构建可以连续执行几个命令行指令。\ndocker build -f elasticsearch.Dockerfile -t my-elastic . .dockerignore 文件\n在Docker CLI将上下文发送到Docker守护程序之前，它将在上下文的根目录中查找名为.dockerignore的文件。如果此文件存在，则CLI会修改上下文以排除与其中的模式匹配的文件和目录。这有助于避免不必要地将大型文件或敏感文件和目录发送到守护程序，并避免使用ADD或COPY将它们添加到映像中。\n规则 行为 # comment 忽略这个 */temp* 在根的任何直接子目录中排除名称以temp开头的文件和目录。例如，排除纯文件/somedir/temporary.txt，以及目录/somedir/temp */*/temp* 从根以下两级的任何子目录中排除以temp开头的文件和目录。例如，排除/somedir/subdir/temporary.txt temp? 排除名称为temp的一个字符扩展名的根目录中的文件和目录。例如，排除/ tempa和/ tempb。 dockerfile命令:\nFROM \u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;] [AS \u0026lt;name\u0026gt;]]: 挑选一个基础镜像作为基础，FROM指令初始化一个新的构建阶段，并为后续指令设置基本映像。因此，有效的Dockerfile必须以FROM指令开头。 RUN RUN \u0026lt;command\u0026gt; (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows) RUN [\u0026quot;executable\u0026quot;, \u0026quot;param1\u0026quot;, \u0026quot;param2\u0026quot;] (exec form) RUN指令将在当前映像顶部的新层中执行任何命令，并提交结果。生成的提交映像将用于Dockerfile中的下一步。 在shell形式中，可以使用\\（反斜杠）将一条RUN指令继续到下一行 CMD CMD [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] (exec form, this is the preferred form) CMD [\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] (as default parameters to ENTRYPOINT) CMD command param1 param2 (shell form) Dockerfile中只能有一条CMD指令。如果您列出多个CMD，则只有最后一个CMD才会生效。 EXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;/\u0026lt;protocol\u0026gt;...]: EXPOSE指令通知Docker运行时容器在指定的网络端口上进行侦听。您可以指定端口是侦听TCP还是UDP，如果未指定协议，则默认值为TCP。 ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;: ENV指令将环境变量设置为值。此值将在构建阶段中所有后续指令的环境中使用，并且在许多情况下也可以内联替换。 ADD ADD [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; ADD [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] [\u0026quot;\u0026lt;src\u0026gt;\u0026quot;,... \u0026quot;\u0026lt;dest\u0026gt;\u0026quot;] (路径上有空格必须使用这种方式) ADD指令从\u0026lt;src\u0026gt;复制新文件，目录或远程文件URL，并将它们添加到映像的文件系统中的路径\u0026lt;dest\u0026gt; 源文件解释: ADD hom* /mydir/ adds all files starting with \u0026ldquo;hom\u0026rdquo; ADD hom?.txt /mydir/ ? is replaced with any single character, e.g., \u0026ldquo;home.txt\u0026rdquo; 目标文件解释: ADD test relativeDir/ adds \u0026ldquo;test\u0026rdquo; to WORKDIR/relativeDir/ ADD test /absoluteDir/ adds \u0026ldquo;test\u0026rdquo; to /absoluteDir/ COPY只能是本地文件 ENTRYPOINT启动容器会执行 示例(Dockerfile)\nFROM openjdk:11 WORKDIR /book COPY ./book-service-0.0.1-SNAPSHOT.jar /book/book.jar EXPOSE 9700 ENTRYPOINT [\u0026quot;java\u0026quot;, \u0026quot;-jar\u0026quot;, \u0026quot;book.jar\u0026quot;, \u0026quot;--spring.profiles.active=release\u0026quot;] docekr compose 功能列表\nCompose是用于定义和运行多容器Docker应用程序的工具。通过Compose，您可以使用YAML文件来配置应用程序的服务。然后，使用一个命令，就可以从配置中创建并启动所有服务\n光听很懵逼，实际体验一下\n需要一个.yml的配置文件(docker-compose.yml)，我这里用docker-compose同时部署java服务和MongoDB作为演示\nversion: '3.5' services: mongo: image: mongo container_name: book-mongo ports: - 27010:27017 environment: MONGO_INITDB_ROOT_USERNAME: admin MONGO_INITDB_ROOT_PASSWORD: password volumes: - /docker-data/mongodb/:/data/db/ networks: - kazma_net restart: always blog: build: context: ./ dockerfile: Dockerfile container_name: book-service volumes: - ~/book-service-logs:/book-service-logs ports: - 9700:9700 networks: - kazma_net restart: always depends_on: - mongo networks: kazma_net: name: kazma_network 然后执行\ndocker-compose -f docker-compose.yml up -d 将会自动构建Dockerfile并且创建好MongoDB的环境\n关于上面的指令\nversion: 表示使用的docker-compose的版本，版本不同有一些命令不一样 services: 下面就是所有的docker container了 mongo和blog是自定义的名字，用于区分不同的配置，这里分别是配置MongoDB和java服务 image和build: image表示使用docekr shop里的镜像，而build则使用指定的Dockerfile构建的镜像 container_name: 可以指定容器的名称 ports: 暴露出去端口并且映射到本地，是数组，可以有多个 volumes: 绑定挂载卷，用于容器卷和本地卷绑定，其实和docekr run的-v一样，然后这个也是数组 environment: 环境变量，也是数组 networks: 新建一个网段或者使用，我在最后新建了叫kazma_net的网络，然后在前面指定使用 restart: 是否重启always depends_on: 依赖某些容器，等某些容器先启动后再启动这个容器，我这里很明显java服务依赖mongo的服务 其他\ndocker-compose stop docker-compose restart ocker-compose down -v .env\n和docker-compose.yml处于同级目录，是docker-compose的环境配置，可以在docker-compose.yml中使用${xxx}来引用\n语法： VAR=VAL格式 #号开头将会被忽略 空行会被忽略 如果是VAR=\u0026ldquo;VAL\u0026rdquo;，那么\u0026quot;也是字符串，不会被处理 ","date":"2019-02-01","permalink":"https://kazma233.github.io/posts/2019-02/docker%E5%B0%8F%E8%AE%B0/","tags":["笔记"],"title":"docker的小笔记"},{"content":"windows上的包管理工具。\n如题，在Mac上有homebrew这样的神器，叫包管理工具，而在Windows上却很少有这样的工具，不过今天要介绍的这款命令行工具就算是包管理工具(官方叫法是Windows的命令行安装程序)。\n介绍 scoop是Windows的命令行安装程序\n安装 安装需要 Powershell 3以上(windows10应该都是没问题的，win7，8还有人用吗?) .NET Framework 4.5以上(自己检查一下就好了，没有安装一个) Pwoershell要允许执行用户自定义的脚本, 运行该命令: set-executionpolicy remotesigned -s currentuser，然后输入A回车就好了。 开始安装 只需要在命令行输入iex (new-object net.webclient).downloadstring('https://get.scoop.sh')即可 说明 安装好之后scoop和它安装的软件都在C:\\Users\\\u0026lt;user\u0026gt;\\scoop下，使用--global命令安装的在C:\\ProgramData\\scoop下，如果需要自定义安装scoop的路径，可以设置环境变量SCOOP和SCOOP_GLOBAL来指定安装路径和全局安装路径 建议先设置代理(小飞机默认设置): scoop config proxy 127.0.0.1:1080 建议新增安装包bucket(有点像软件源)：scoop bucket add java,scoop bucket add extras,scoop bucket add versions 可以用search搜索你需要的软件 ,java bucket里有很多版本的java 然后可以尝试安装你需要的软件: scoop install python27,scoop install python36 使用reset切换软件版本: scoop reset python27，目测python切换会有问题，自己去PATH里删掉C:\\Users\\\u0026lt;user\u0026gt;\\scoop\\apps\\python36\\current就好了,java切换可以像这样，是没问题的 使用uninstall来进行卸载 其他可以运行scoop help来查看具体的作用 部分来源 少数派: 「一行代码」搞定软件安装卸载，用 Scoop 管理你的 Windows 软件\n","date":"2019-01-23","permalink":"https://kazma233.github.io/posts/windows%E4%B8%8A%E7%9A%84homebrew%E4%B9%8Bscoop%E7%9A%84%E4%BD%BF%E7%94%A8/","tags":["教程","scoop"],"title":"windows上的homebrew之scoop的使用"},{"content":"Shadowsocks(弃)\n中国大陆对很多好用的国外网站进行了封锁，说实话对开发人员来说造成了巨大的阻碍。互联网作为连接世界的工具，把它屏蔽了更像是开倒车。而且作为一个开发人员，至少的话会用到Google搜索问题，然而你也不能使用。偶尔想去看看国外人民的水深火热，也做不到。\n在这样的环境下，催生了一大波的代理工具，用于突破封锁解除限制，shadowsocks就是这么一款工具。\n原理 有一台中间服务器，这台服务器（后面要做的事情就在这台服务器上，一般是在海外，离大陆越近一般情况下延迟会越低，体验也会越好）必须是能够访问那些被封锁的网站的，在本地通过代理客户端去连接中间服务器，中间服务端帮你把请求发送到被封锁网站的服务器上，然后中间服务器接收到被封锁网站的响应再返回给本地客户端，如下:\n本地 x\u0026gt; 封锁的网站\n本地 -\u0026gt; 中间服务器 -\u0026gt; 封锁的网站\n安装 系统需要是Ubuntu(其他Linux发行版本其实也类似，只不过install命令不同)，目前用的是16.04的长期支持版本，新的长期支持版本也是可以的\n更新系统的软件目录列表: apt-get update\n安装python的pip软件包管理工具: apt-get install -y python-pip\n安装shadowsocks: pip install shadowsocks\n配置shadowsocks\n新建并编辑(使用擅长的文本编辑工具即可[vim,vi]): /opt/shadowsocks.json\n{ \u0026quot;server\u0026quot;:\u0026quot;0.0.0.0\u0026quot;, \u0026quot;server_port\u0026quot;:11223, \u0026quot;local_address\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;local_port\u0026quot;:1080, \u0026quot;password\u0026quot;:\u0026quot;123456\u0026quot;, \u0026quot;timeout\u0026quot;:300, \u0026quot;method\u0026quot;:\u0026quot;chacha20\u0026quot;, \u0026quot;fast_open\u0026quot;: false } server是指服务器的ip，如果指定当前服务器ip出错，可以像我一样使用0.0.0.0，表示所有ip server_port服务监听的端口，用于客户端连接 local_address本地监听地址，默认回环地址127.0.0.1就行了，服务器上默认就行了 local_port本地监听的端口，同上 password代理服务器密码 timeout超时时间 method数据传说的加密方式，如果这里用的是chacha20的话，那后面服务器需要安装chacha20的支持，不想设置可以填aes-256-cfb 设置chacha20（可跳过，具体看上方method）\nwget https://github.com/jedisct1/libsodium/releases/download/1.0.17/libsodium-1.0.17.tar.gz tar xf libsodium-1.0.16.tar.gz cd libsodium ./configure make -j2 make install ldconfig 启动 ssserver -c /opt/shadowsocks.json -d start\n-c 指定配置文件地址 -d 指定命令start, restart, stop 其他 开机启动代理服务器 编辑 /etc/rc.local 在弹出的编辑框里的\u0026quot;exit 0 \u0026ldquo;这句之前添加一行/usr/local/bin/ssserver -c /opt/shadowsocks.json -d start 如果安装shadowsocks的时候pip提示没有安装setuptools，安装一下就好了 如果在安装chacha20时没有c编译器，执行apt-get install build-essential 参考 shadowsocks的wiki(推荐) shadowsocks github主页 windows的客户端 MAC的客户端 安卓客户端 记录 shadowscoks-libv: 混淆 (忽视)\nhttps://github.com/shadowsocks/simple-obfs-android/issues https://github.com/iMeiji/shadowsocks_install/wiki/shadowsocks-libev https://github.com/shadowsocks/shadowsocks-libev ","date":"2018-12-11","permalink":"https://kazma233.github.io/posts/shadowsocks%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E5%AE%89%E8%A3%85/","tags":["教程","shadowsocks","wall"],"title":"Shadowsocks的服务器端安装"},{"content":"CountDownLatch和CyclicBarrier 这两个java并发的工具类还是很常用的，还有一个Semaphore(信号量)，看看他们分别是怎样使用的。\n我第一次看到这三个工具类也是在Java并发编程实战上看到的，写下笔记增加点印象。\nCountDownLatch 首先来看CountDownLatch，有人是这样比喻的:\n百米赛跑，十名运动员同时起跑，由于速度的快慢，肯定有先到达和后到达的，而终点有个统计成绩的仪器，当所有选手到达终点时，它会统计所有人的成绩并进行排序，然后把结果发送到汇报成绩的系统。 来源\nCountDownLatch来源于jdk@since 1.5，他的作用就像刚才描述的例子那样，把运动员看成是不同的线程，主线程(统计的人)需要等待await()其他线程(运动员)都执行执行到终点countDown()，才进行后续的操作，比如: 成绩排序，发送汇总结果等等。\n来看看CountDownLatch的API\n构造函数\npublic CountDownLatch(int count) { }; //参数count为计数值 方法\npublic void await() throws InterruptedException { }; //调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行 public boolean await(long timeout, TimeUnit unit) throws InterruptedException { }; //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行 public void countDown() { }; //将count值减1 下面是我参考写出来的例子(使用junit4):\npublic class CountDownLatchTest { private static final Integer THREAD_COUNT = 2; @Test public void main() throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(THREAD_COUNT); for (int i = 1; i \u0026lt;= THREAD_COUNT; i++) { new Thread(new MyRunable(i + \u0026quot;\u0026quot;, i * 1000L, countDownLatch)).start() ; } countDownLatch.await(); System.out.println(\u0026quot;All Over\u0026quot;); } public class MyRunable implements Runnable { private String name; private Long time; private CountDownLatch countDownLatch; public MyRunable(String name, Long time, CountDownLatch countDownLatch) { this.name = name; this.countDownLatch = countDownLatch; this.time = time; } @Override public void run() { System.out.println(name + \u0026quot;: run\u0026quot;); try { Thread.sleep(time); System.out.println(name + \u0026quot;: over\u0026quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { countDownLatch.countDown(); } } } } CyclicBarrier CyclicBarrier，也是在@since 1.5加入的并发控制工具类，它可以让线程进行互相等待await()，当一个线程先执行完某些任务时，他会被阻塞(Barrier)，直到所有线程都执行到这个状态时，这些线程才能继续往后执行其他任务。CycliBarrier对象可以重复使用，重用之前应当调用reset()。\n它有两个构造函数\n// parties表示要多少个线程需要等待 // barrierAction为当这些线程都达到barrier状态时将会执行 public CyclicBarrier(int parties, Runnable barrierAction); public CyclicBarrier(int parties); 主要API\n// 等待其他线程 应该是最常用的方法了 public int await() public int await(long timeout, TimeUnit unit) // 重置CyclicBarrier public void reset() // 获得CyclicBarrier阻塞的线程数量 public int getNumberWaiting() // 用来知道阻塞的线程是否被中断 public boolean isBroken() 下面看一个实例(同样用junit4测试):\npublic class CyclicBarrierTest { private static final Integer THREAD_COUNT = 2; @Test public void main() throws IOException { CyclicBarrier cyclicBarrier = new CyclicBarrier(THREAD_COUNT, new Runnable() { @Override public void run() { System.out.println(\u0026quot;over\u0026quot;); } }); for (int i = 0; i \u0026lt; THREAD_COUNT; i++) { new Thread(new WriteRunable(i + \u0026quot;\u0026quot;, cyclicBarrier)).start(); } System.in.read(); } public class WriteRunable implements Runnable { private String name; private CyclicBarrier cyclicBarrier; public WriteRunable(String name, CyclicBarrier cyclicBarrier) { this.name = name; this.cyclicBarrier = cyclicBarrier; } @Override public void run() { try { double v = Math.random() * 10000d; System.out.println(v); Thread.sleep((long) v); } catch (InterruptedException e) { e.printStackTrace(); } finally { try { System.out.println(\u0026quot;任务完成: \u0026quot; + name); cyclicBarrier.await(); // 等待其他线程完成后再继续执行 } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } } System.out.println(\u0026quot;继续后续任务\u0026quot;); } } } Semaphore Semaphore翻译成字面意思为 信号量，Semaphore可以控制同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。\n构造函数\n// 参数permits表示许可数目，即同时可以允许多少线程进行访问 public Semaphore(int permits) { sync = new NonfairSync(permits); } // 这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可 public Semaphore(int permits, boolean fair) { sync = (fair)? new FairSync(permits) : new NonfairSync(permits); } 重要的方法\n// 获取一个许可 public void acquire() // 获取permits个许可 public void acquire(int permits) // 释放一个许可 public void release() // 释放permits个许可 public void release(int permits) // 尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回false public boolean tryAcquire() // 尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false public boolean tryAcquire(long timeout, TimeUnit unit) // 尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回false public boolean tryAcquire(int permits) // 尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false public boolean tryAcquire(int permits, long timeout, TimeUnit unit) // Returns the current number of permits available in this semaphore. public int availablePermits() 假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现\npublic class Test { public static void main(String[] args) { int N = 8; //工人数 Semaphore semaphore = new Semaphore(5); //机器数目 for(int i=0;i\u0026lt;N;i++) new Worker(i,semaphore).start(); } static class Worker extends Thread{ private int num; private Semaphore semaphore; public Worker(int num,Semaphore semaphore){ this.num = num; this.semaphore = semaphore; } @Override public void run() { try { semaphore.acquire(); System.out.println(\u0026quot;工人\u0026quot;+this.num+\u0026quot;占用一个机器在生产...\u0026quot;); Thread.sleep(2000); System.out.println(\u0026quot;工人\u0026quot;+this.num+\u0026quot;释放出机器\u0026quot;); semaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } } } } 文中Semaphore用法全来源于引用1.\n引用:\nJava并发编程：CountDownLatch、CyclicBarrier和Semaphore Java并发包中CyclicBarrier的工作原理、使用示例 并发工具类（二）同步屏障CyclicBarrier ","date":"2018-09-03","permalink":"https://kazma233.github.io/posts/countdownlatch%E5%92%8Ccyclicbarrier/","tags":["教程","并发工具"],"title":"CountDownLatch和CyclicBarrier"},{"content":"String(jdk1.8)源码解读，了解String在java的处理方式。\n简介 在java语言中用String表示字符串，从下面定义可以看出String是final类型的，所以是不可变的，线程安全的，不可被继承。\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence 其中实现了三个实现接口: Serializable用于字符串序列化, Comparable用于字符串比较 ,CharSequence表示char值的一个可读序列。此接口对许多不同种类的char序列提供统一的自读访问。\n主要的属性 /** 存储字符串 */ private final char value[]; /** 缓存字符串对象的哈希值，默认值为0 */ private int hash; // Default to 0 下面这个属性在jdk1.8中没有看到private final byte coder经查证发现是在jdk9中加入的一 个对象\n字符串在 Java 的 String 类内部由一个包含该字符串中所有字符的 char[] 来表示，其中的每个字符 char 又是由 2 个字节组成，因为 Java 内部使用 UTF-16。举例来说，如果一个字符串含有英文字符，那么这些英文字符的前 8 比特都将为 0，因为一个ASCII字符都能被单个字节来表示。 当然有许多字符需要 16 比特，但从统计角度来说只需 8 比特的情况占大多数，例如：LATIN-1 ，因此这能成为一种改善内存占用及性能的一个机会。更重要的是：由于 JVM 存储字符串的方式导致 JVM 堆空间通常很大一部分都被字符串所占据。 大多数情况下，字符串实例常占用比它实际需要的内存多一倍的空间。 Java 9 重新采纳字符串压缩这一概念。 这意味着无论何时我们创建一个所有字符都能用一个字节的 LATIN-1 编码来描述的字符串，都将在内部使用字节数组的形式存储，且每个字符都只占用一个字节。另一方面，如果字符串中任一字符需要多于 8 比特位来表示时，该字符串的所有字符都统统使用两个字节的 UTF-16 编码来描述。因此基本上能如果可能，都将使用单字节来表示一个字符。 现在的问题是：所有的字符串操作如何执行？ 怎样才能区分字符串是由 LATIN-1 还是 UTF-16 来编码？为了处理这些问题，字符串的内部实现进行了一些调整。引入了一个 final 修饰的成员变量 coder, 由它来保存当前字符串的编码信息。 来源\n其中两种格式定义如下:\nstatic final byte LATIN1 = 0; static final byte UTF16 = 1; 主要的方法 // String的字符长度 public int length() { return value.length; // 返回char数组的长度 } // 截取字符串(能取到beginIndex,取不到endIndex位置的字符) public String substring(int beginIndex, int endIndex); // 正则匹配 public boolean matches(String regex); // 拆分字符串 public String[] split(String regex); // 获得char数组 // 不指定编码会使用默认的编码 public byte[] getBytes(); public byte[] getBytes(String charsetName); public byte[] getBytes(Charset charset); // 比较字符串 // 单纯的比较(一个个字符去比较，不能使用==去比较，因为比较的是字符串的引用) public boolean equals(Object anObject); // 忽略大小写的比较 public boolean equalsIgnoreCase(String anotherString); 其他 String s1 = \u0026quot;www\u0026quot;; String s2 = \u0026quot;ccc\u0026quot;; String s3 = s1 + s2; 编译器其实会对+进行了转换的，转成了 StringBuilder 对象来操作了，首先使用 s1 创建 StringBuilder 对象，然后用 append方法连接 s2，最后调用toString方法完成。\n但是在下面这种情况下\nString s = \u0026quot;www\u0026quot;; for (int i = 0; i \u0026lt; 10; i++) s += i; 这样循环中每次都要创建 StringBuilder 对象，而且要调用toString方法，这样的执行效率显然比较低，而且增加了 GC 的压力。\n把事情都丢给编译器是不友好的，为了能让程序执行更加高效，最好是我们自己来控制 StringBuilder 的实例，只创建一个 StringBuilder 实例，后面用append方法连接字符串\n","date":"2018-08-20","permalink":"https://kazma233.github.io/posts/string%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","tags":["教程","String","源码"],"title":"String源码解析"},{"content":"这篇文章是自己想去了解HashMap(jdk1.8)的原理和数据结构，通过各大博客和书籍整理出来的，所以可能会没有节奏感。\nHashMap的定义 public class HashMap\u0026lt;K,V\u0026gt; extends AbstractMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, Serializable HashMap()是一个默认的构造器，初始容量16，负载因子为0.75. HashMap(int initialCapacity)是一个指定初始容量为initialCapacity，负载因子为0.75的空的hashmap。 HashMap(int initialCapacity, float loadFactor)是一个指定初始容量为initialCapacity，负载因子为loadFactor的空的HashMap。 HashMap的特点 HashMap是哈希表(根据键（Key）而直接访问在内存存储位置的数据结构, 也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做散列表。) HashMap不是同步的(即线程不安全的), 如果多个线程同时对一HashMap的集合试图做迭代时有结构的上改变（添加、删除entry，只改变entry的value的值不算结构改变），那么会报ConcurrentModificationException，专业术语叫fail-fast，尽早报错对于多线程程序来说是很有必要的。 不保证其内部元素的顺序，而且随着时间的推移，同一元素的位置也可能改变（resize的情况） HashMap的key、value都可以为null(null得key存放在table[0]) HashMap的一些属性 /** * HashMap默认的初始化大小 - 大小必须是2的次方. */ static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; // aka 16 /** * HashMap的最大值 */ static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; /** * 默认的负载因子的值 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * table在首次使用时初始化，并根据需要调整大小。分配时，长度始终是2的幂 */ transient Node\u0026lt;K,V\u0026gt;[] table; /** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet; /** * 当前HashMap大小 */ transient int size; /** * fail-fast 机制 * * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount; /** * 下次扩容的临界值,HashMap大小(size)超过threshold大小, HashMap会自动扩容(capacity * load factor) */ int threshold; /** * 负载因子 */ final float loadFactor; 负载因子: 当负载因子较大时，去给table数组扩容的可能性就会少，所以相对占用内存较少（空间上较少），但是每条entry链上的元素会相对较多，查询的时间也会增长（时间上较多）。反之就是，负载因子较少的时候，给table数组扩容的可能性就高，那么内存空间占用就多，但是entry链上的元素就会相对较少，查出的时间也会减少。所以才有了负载因子是时间和空间上的一种折中的说法。\nEntry是HashMap的内部类，它继承了Map中的Entry接口，它定义了键(key)，值(value)，和下一个节点的引用(next)，以及hash值。很明确的可以看出Entry是什么结构，它是单线链表的一个节点。也就是说HashMap的底层结构是一个数组，而数组的元素是一个单向链表。\nhash碰撞 至于为什么要这样设计?我们来谈谈hash碰撞\n哈希表定义\nHash ，一般翻译做“散列” ，也有直接音译为“哈希”的，就是把任意长度的输入（又叫做预映射，pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。\n这种转换是一种压缩映射，也就是散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，而不可能从散列值来唯一的确定输入值。 简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。\nHASH 主要用于信息安全领域中加密算法，它把一些不同长度的信息转化成杂乱的128位的编码, 这些编码值叫做sHASH值\n上图HashMap里面的bucket出现了单链表的形式，散列表要解决的一个问题就是散列值的冲突问题(两个不同的key但是hash出来的值是相同的)，通常是两种方法：链表法和开放地址法。链表法就是将相同hash值的对象组织成一个链表放在hash值对应的槽位；开放地址法是通过一个探测算法，当某个槽位已经被占据的情况下继续查找下一个可以使用的槽位。java.util.HashMap采用的链表法的方式，链表是单向链表。\nput函数的实现 对key的hashCode()做hash，然后再计算index 如果没碰撞直接放到bucket里 如果碰撞了，以链表的形式存在buckets后 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了(超过load_factor * capacity)，就要resize get函数的实现 bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry 若为树，则在树中通过key.equals(k)查找，O(logn) 若为链表，则在链表中通过key.equals(k)查找，O(n) 一些概念 以Entry[]数组实现的哈希桶数组，用Key的哈希值取模桶数组的大小可得到数组下标。 插入元素时，如果两条Key落在同一个桶（比如哈希值1和17取模16后都属于第一个哈希桶），我们称之为哈希冲突。 JDK的做法是链表法，Entry用一个next属性实现多个Entry以单向链表存放。查找哈希值为17的key时，先定位到哈希桶，然后链表遍历桶里所有元素，逐个比较其Hash值然后key值。 在JDK8里，新增默认为8的阈值，当一个桶里的Entry超过閥值，就不以单向链表而以红黑树来存放以加快Key的查找速度。 当然，最好还是桶里只有一个元素，不用去比较。所以默认当Entry数量达到桶数量的75%时，哈希冲突已比较严重，就会成倍扩容桶数组，并重新分配所有原来的Entry。扩容成本不低，所以也最好有个预估值。 取模用与操作（hash \u0026amp; （arrayLength-1））会比较快，所以数组的大小永远是2的N次方， 你随便给一个初始值比如17会转为32。默认第一次放入元素时的初始值是16。 iterator（）时顺着哈希桶数组来遍历，看起来是个乱序。 引用:\n关于Java集合的小抄 Java HashMap工作原理及实现 Java HashMap 源码解析 Java 集合干货系列 -（三）HashMap 源码解析 深入理解HashMap ","date":"2018-08-07","permalink":"https://kazma233.github.io/posts/hashmap%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%E6%80%BB%E7%BB%93/","tags":["教程","源码"],"title":"HashMap源码解读总结"}]